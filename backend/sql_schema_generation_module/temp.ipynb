{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y2cEo8njl4ILkxIsLfMZ5IAQYb38SkklHvFZ'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "# from weaviate.classes.init import Auth\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# weaviate_url = os.getenv(\"WEAVIATE_URL\") \n",
    "# weaviate_api_key = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "# weaviate_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "weaviate_url=\"https://9yqwkasqgihqvmw3koycg.c0.asia-southeast1.gcp.weaviate.cloud\"\n",
    "weaviate_api_key=\"yTIQQldOtWhMlkmVPx2Fan3o6ZyVEgv32573\"\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=weaviate_url , auth_client_secret=weaviate.AuthApiKey(weaviate_api_key),\n",
    "    additional_headers={\n",
    "         \"X-HuggingFace-Api-Key\": HF_TOKEN\n",
    "    },\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'RAG',\n",
       "   'description': 'Documents for RAG',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-huggingface': {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "     'type': 'text',\n",
       "     'useCache': True,\n",
       "     'useGPU': False,\n",
       "     'vectorizeClassName': True,\n",
       "     'waitForModel': False}},\n",
       "   'multiTenancyConfig': {'autoTenantActivation': False,\n",
       "    'autoTenantCreation': False,\n",
       "    'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'The content of the paragraph',\n",
       "     'indexFilterable': True,\n",
       "     'indexRangeFilters': False,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-huggingface': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'asyncEnabled': False,\n",
       "    'deletionStrategy': 'NoAutomatedResolution',\n",
       "    'factor': 1},\n",
       "   'shardingConfig': {'actualCount': 1,\n",
       "    'actualVirtualCount': 128,\n",
       "    'desiredCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'function': 'murmur3',\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'virtualPerPhysical': 128},\n",
       "   'vectorIndexConfig': {'bq': {'enabled': False},\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'distance': 'cosine',\n",
       "    'dynamicEfFactor': 8,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfMin': 100,\n",
       "    'ef': -1,\n",
       "    'efConstruction': 128,\n",
       "    'filterStrategy': 'sweeping',\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'maxConnections': 32,\n",
       "    'multivector': {'aggregation': 'maxSim', 'enabled': False},\n",
       "    'pq': {'bitCompression': False,\n",
       "     'centroids': 256,\n",
       "     'enabled': False,\n",
       "     'encoder': {'distribution': 'log-normal', 'type': 'kmeans'},\n",
       "     'segments': 0,\n",
       "     'trainingLimit': 100000},\n",
       "    'skip': False,\n",
       "    'sq': {'enabled': False, 'rescoreLimit': 20, 'trainingLimit': 100000},\n",
       "    'vectorCacheMaxObjects': 1000000000000},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-huggingface'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client.schema.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'RAG',\n",
       "   'description': 'Documents for RAG',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-huggingface': {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "     'type': 'text',\n",
       "     'useCache': True,\n",
       "     'useGPU': False,\n",
       "     'vectorizeClassName': True,\n",
       "     'waitForModel': False}},\n",
       "   'multiTenancyConfig': {'autoTenantActivation': False,\n",
       "    'autoTenantCreation': False,\n",
       "    'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'The content of the paragraph',\n",
       "     'indexFilterable': True,\n",
       "     'indexRangeFilters': False,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-huggingface': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'asyncEnabled': False,\n",
       "    'deletionStrategy': 'NoAutomatedResolution',\n",
       "    'factor': 1},\n",
       "   'shardingConfig': {'actualCount': 1,\n",
       "    'actualVirtualCount': 128,\n",
       "    'desiredCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'function': 'murmur3',\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'virtualPerPhysical': 128},\n",
       "   'vectorIndexConfig': {'bq': {'enabled': False},\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'distance': 'cosine',\n",
       "    'dynamicEfFactor': 8,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfMin': 100,\n",
       "    'ef': -1,\n",
       "    'efConstruction': 128,\n",
       "    'filterStrategy': 'sweeping',\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'maxConnections': 32,\n",
       "    'multivector': {'aggregation': 'maxSim', 'enabled': False},\n",
       "    'pq': {'bitCompression': False,\n",
       "     'centroids': 256,\n",
       "     'enabled': False,\n",
       "     'encoder': {'distribution': 'log-normal', 'type': 'kmeans'},\n",
       "     'segments': 0,\n",
       "     'trainingLimit': 100000},\n",
       "    'skip': False,\n",
       "    'sq': {'enabled': False, 'rescoreLimit': 20, 'trainingLimit': 100000},\n",
       "    'vectorCacheMaxObjects': 1000000000000},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-huggingface'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"RAG\",\n",
    "            \"description\": \"Documents for RAG\",\n",
    "            \"vectorizer\": \"text2vec-huggingface\",\n",
    "            \"moduleConfig\": {\"text2vec-huggingface\": {\"model\": \"sentence-transformers/all-MiniLM-L6-v2\", \"type\": \"text\"}},\n",
    "            \"properties\": [\n",
    "                {\n",
    "                    \"dataType\": [\"text\"],\n",
    "                    \"description\": \"The content of the paragraph\",\n",
    "                    \"moduleConfig\": {\n",
    "                        \"text2vec-huggingface\": {\n",
    "                            \"skip\": False,\n",
    "                            \"vectorizePropertyName\": False,\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"content\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "     \n",
    "\n",
    "client.schema.create(schema)\n",
    "     \n",
    "\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_22224\\556607351.py:4: LangChainDeprecationWarning: The class `WeaviateHybridSearchRetriever` was deprecated in LangChain 0.3.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-weaviate package and should be used instead. To use it run `pip install -U :class:`~langchain-weaviate` and import as `from :class:`~langchain_weaviate import WeaviateVectorStore``.\n",
      "  retriever = WeaviateHybridSearchRetriever(\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever\n",
    "     \n",
    "\n",
    "retriever = WeaviateHybridSearchRetriever(\n",
    "    alpha = 0.5,               # defaults to 0.5, which is equal weighting between keyword and semantic search\n",
    "    client = client,           # keyword arguments to pass to the Weaviate client\n",
    "    index_name = \"RAG\",  # The name of the index to use\n",
    "    text_key = \"content\",         # The name of the text key to use\n",
    "    attributes = [], # The attributes to return in the results\n",
    "    create_schema_if_missing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "\n",
    "# List of URLs to fetch and embed into the vector database\n",
    "docs_urls = [\n",
    "    \"https://docs.oracle.com/cd/B10500_01/olap.920/a95295/designd5.htm\",\n",
    "    \"https://olap.com/learn-bi-olap/tutorials/olap-basics-creating-olap-database/\",\n",
    "    \"https://docs.oracle.com/cd/A97630_01/olap.920/a95295/designd6.htm\"\n",
    "]\n",
    "\n",
    "# Load documents from the provided URLs\n",
    "loaders = [RecursiveUrlLoader(url) for url in docs_urls]\n",
    "\n",
    "# Extract documents\n",
    "documents = []\n",
    "for loader in loaders:\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "# The extracted documents can now be stored in a vector database\n",
    "# Example: Store in a ChromaDB or FAISS vector store\n",
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "     \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000,chunk_overlap=500)\n",
    "     \n",
    "\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "print(len(documents))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0a1a15c9-e009-4ee9-8506-af50520a026f',\n",
       " '7c9bad43-26df-477e-8a87-a046551d84a9',\n",
       " '18ebf4cb-325c-4d80-a130-af4418dd9178',\n",
       " '67bd7264-996d-43d8-8c95-803596b82896',\n",
       " '1e79e4d8-4617-4984-82be-91463ba90f5a',\n",
       " '589d228b-5598-44c5-95c2-7afbc1fef676',\n",
       " 'd7ff68a0-babc-4930-8041-b15728ee9441',\n",
       " '9cacbca7-1707-4fe2-9383-29e351367bce',\n",
       " 'ee34804b-1b2f-4f74-bacb-ba3a1fc5f3b7',\n",
       " '6a5ac6bd-d63c-4cab-bc73-e477cb46c24c',\n",
       " '2b004f69-f18b-4195-ae9d-b729bf0298bc',\n",
       " '499a3d76-68e0-47cd-b441-b91749456b6c',\n",
       " '6415dc17-3cec-4ebc-9389-2d81ec419b48',\n",
       " '4b81ae86-f0e6-408e-857c-cbf3e0e5fb5f',\n",
       " '4ca679f9-c526-48ba-a9f0-c341c3568b25',\n",
       " '45715088-cb57-4e41-acc4-3501a50173e4',\n",
       " '7b9a5e89-6f2d-49ed-98bf-2a8351892e35',\n",
       " '78b16a61-8a1b-41d1-a0a2-c0979c2fee8b',\n",
       " '28970ebf-8ef5-48f6-8475-0d874014a814',\n",
       " 'ccc9bce7-007d-447a-96e6-7f79088581da',\n",
       " '0823a1ef-47ec-4016-9267-9640ba9c8169',\n",
       " '415f7714-0d91-44dd-823b-751e61e5cf76',\n",
       " 'd444b631-bd8b-4b7c-a635-79fc86376ba8',\n",
       " '308373d7-2aab-48bc-8e89-ae30324b7115']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(retriever.invoke(\"what is the best OLAP practices for creating 3 4 tables ?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "Etl , O l AP and t rends\n",
      "Features ROLAP MOLAP HOLAP\n",
      "Storage space \n",
      "requirement\n",
      "Data is stored in \n",
      "relational tables. \n",
      "Comparatively \n",
      "Large storage \n",
      "space requirement \n",
      "Data is stored in \n",
      "multidimensional \n",
      "tables. Medium \n",
      "storage space \n",
      "requirements\n",
      "It uses both \n",
      "ROLAP, \n",
      "MOLAP. Small \n",
      "storage space \n",
      "requirements. No \n",
      "duplicate of data\n",
      "Latency Low latency High latency Medium latency \n",
      "Query response \n",
      "time\n",
      "Slow query \n",
      "response time \n",
      "Fast query \n",
      "response time.\n",
      "Medium query \n",
      "response time \n",
      "Volume of data Used for large \n",
      "volumes of data\n",
      "Limited volume of \n",
      "data\n",
      "Can be used in \n",
      "both scenarios\n",
      "Retreival of data Complex SQL \n",
      "queries are used\n",
      "Sparse Matrix is \n",
      "used\n",
      "Both\n",
      "Data View Static view of data Dynamic view of \n",
      "data\n",
      "Both static and \n",
      "dynamic view of \n",
      "data\n",
      "2)\n",
      " Limitations of OLA\n",
      "P cube are:\n",
      "\t •\t OLAP\n",
      "\t\n",
      "requires\n",
      "\t\n",
      "a\n",
      "\t\n",
      "star/snowflake\n",
      "\t\n",
      "schema:\n",
      "\t •\t \tThere\n",
      "\tis\n",
      "\ta\n",
      "\tlimited\n",
      "\tnumber\n",
      "\tof\n",
      "\tdimensions\n",
      "\t(fields)\n",
      "\ta\n",
      "\tsingle\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tIt\n",
      "\tis\n",
      "\tnearly\timpossible\n",
      "\tto\n",
      "\taccess\n",
      "\ttransactional\n",
      "\tdata\n",
      "\tin\n",
      "\tthe\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tChanges\n",
      "\tto\n",
      "\tan\n",
      "\tOLAP\n",
      "\tcube\n",
      "\trequires\n",
      "\ta\n",
      "\tfull\n",
      "\tupdate\n",
      "\tof\n",
      "\tthe\n",
      "\tcube\n",
      "\t–\n",
      "\ta\n",
      "\t\n",
      "lengthy process.\n",
      "5.13 FURTHER READINGS\n",
      " y William H. Inmon, Building the Data Warehouse, Wiley, 4th Edition, 2005.\n",
      " y Data Warehousing \n",
      "Fundamentals, Paulraj Ponnaiah, Wiley Student Edition \n",
      " y Data Warehousing, Reema Thareja, Oxford University Press\n",
      " y Data Warehousing, Data Mining & OLAP, Alex Berson and Stephen \n",
      "J.Smith,  Tata McGraw – Hill Edition, 2016.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize Groq client with API key\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Function to get OLAP best practices based on user query\n",
    "def get_olap_best_practices(user_query):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"The user has asked: '{user_query}'. Based on this, provide the best OLAP (Online Analytical Processing) practices. you should answer just related to OLAP and dont include any user query info just give best OLAP practices based on user query \"\n",
    "                           \"Consider data modeling, indexing, partitioning, query optimization, and performance tuning for large-scale analytical workloads.\",\n",
    "                           \n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "    )\n",
    "    \n",
    "    # Get response text\n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Clean up unnecessary formatting (removing ** and #)\n",
    "    cleaned_response = response_text.replace(\"**\", \"\").replace(\"#\", \"\").replace(\"```\",\"\")\n",
    "\n",
    "    return cleaned_response.strip() \n",
    "\n",
    "# Example user query\n",
    "user_query = \"Give me a database table schema for my student management system\"\n",
    "response = get_olap_best_practices(user_query)\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove problematic escape sequences and extra formatting.\"\"\"\n",
    "    text = text.replace(\"**\", \"\").replace(\"#\", \"\")  # Remove markdown formatting\n",
    "    text = text.replace(\"\\\\\", \"\")  # Remove unnecessary backslashes\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    return text\n",
    "\n",
    "# Use the function before invoking the retriever\n",
    "cleaned_response = clean_text(response)\n",
    "print(retriever.invoke(cleaned_response)[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'relevance_score': 0.12646118}, page_content='79\\nIntroduction to Online \\nAnalytical Processing\\n5.6  Data Warehouse and OLAP: Hypercube and Multi   \\nCubes\\nThe OLAP cube is a data structure optimized for very quick data analysis. The OLAP \\nCube consists of numeric facts called measures which are categorized by dimensions. \\nOLAP Cube is also called the hypercube. So, we can say that multidimensional \\nDatabases can we see hypercube and multi cube. Multidimensional cubes have \\nsmaller multiple cubes and in hypercube it seems there is one cube as logically all \\nthe data seems to be as one unit of cube.  Hypercube have multiple same dimensions \\nlogically. The differences of Multi cube and Hyper cube are shown in Table 1 below:Table 1: Differences between Multi cube and Hyper cube\\nMulti Cube Hyper Cube\\nMetadata Each dimension can belong to \\nmany cubes\\nEach dimension belongs to one \\ncube only\\nDimension Not necessary all the dimensions \\nshould belong to some cube\\nEvery dimension owned by a \\nhypercube\\nMeasure \\nComputation\\nComplex, data can be retrieved \\nfrom the all the cubes\\nSimple, as all the numerical \\nfacts are available at one place\\nMultiple multicube system, if there are \\ntwo rows in the DIMENSIONS \\nrowset for which the \\nDIMENSION_NAME value \\nis the same (and the CUBE_\\nNAME value is different), these \\ntwo rows represent the same \\ndimension. As, sub cubes are \\nbuilt from the same pool of \\navailable dimensions.\\nin a multiple hypercube \\nscenario, it is possible for two \\nhypercubes to have a dimension \\nof the same name, each of which \\nhas different characteristics. In \\nthis case, the DIMENSION_\\nUNIQUE_NAME value is \\nguaranteed to be different.\\n5.7 APPLICATIONS OF OLAP\\nOLAP reporting system is widely used in business applications like:\\n•\\t Sales\\n\\t\\nand\\n\\t\\nMarketing\\n•\\t Retail\\n\\t\\nIndustry\\n•\\t Financial\\n\\t\\nOrganizations\\n\\t\\n–\\n\\t\\nBudgeting\\n•\\t Agriculture\\n•\\t People\\n\\t\\nManagement\\n•\\t Process\\n\\t\\nManagement\\nExamples are Essbase from Hyperion Solution and Express Server from Oracle.\\n\\uf043 Check Your Progress 2\\n1) Explain the OLAP application reporting system in Marketing?\\n \\n……………………………………………………………………………\\n……………………………………………………………………………'),\n",
       " Document(metadata={'relevance_score': 0.027169233}, page_content='88\\nEtl , O l AP and t rends\\nFeatures ROLAP MOLAP HOLAP\\nStorage space \\nrequirement\\nData is stored in \\nrelational tables. \\nComparatively \\nLarge storage \\nspace requirement \\nData is stored in \\nmultidimensional \\ntables. Medium \\nstorage space \\nrequirements\\nIt uses both \\nROLAP, \\nMOLAP. Small \\nstorage space \\nrequirements. No \\nduplicate of data\\nLatency Low latency High latency Medium latency \\nQuery response \\ntime\\nSlow query \\nresponse time \\nFast query \\nresponse time.\\nMedium query \\nresponse time \\nVolume of data Used for large \\nvolumes of data\\nLimited volume of \\ndata\\nCan be used in \\nboth scenarios\\nRetreival of data Complex SQL \\nqueries are used\\nSparse Matrix is \\nused\\nBoth\\nData View Static view of data Dynamic view of \\ndata\\nBoth static and \\ndynamic view of \\ndata\\n2)\\n Limitations of OLA\\nP cube are:\\n\\t •\\t OLAP\\n\\t\\nrequires\\n\\t\\na\\n\\t\\nstar/snowflake\\n\\t\\nschema:\\n\\t •\\t \\tThere\\n\\tis\\n\\ta\\n\\tlimited\\n\\tnumber\\n\\tof\\n\\tdimensions\\n\\t(fields)\\n\\ta\\n\\tsingle\\n\\tOLAP\\n\\t\\ncube.\\n\\t\\n•\\t \\tIt\\n\\tis\\n\\tnearly\\timpossible\\n\\tto\\n\\taccess\\n\\ttransactional\\n\\tdata\\n\\tin\\n\\tthe\\n\\tOLAP\\n\\t\\ncube.\\n\\t\\n•\\t \\tChanges\\n\\tto\\n\\tan\\n\\tOLAP\\n\\tcube\\n\\trequires\\n\\ta\\n\\tfull\\n\\tupdate\\n\\tof\\n\\tthe\\n\\tcube\\n\\t–\\n\\ta\\n\\t\\nlengthy process.\\n5.13 FURTHER READINGS\\n y William H. Inmon, Building the Data Warehouse, Wiley, 4th Edition, 2005.\\n y Data Warehousing \\nFundamentals, Paulraj Ponnaiah, Wiley Student Edition \\n y Data Warehousing, Reema Thareja, Oxford University Press\\n y Data Warehousing, Data Mining & OLAP, Alex Berson and Stephen \\nJ.Smith,  Tata McGraw – Hill Edition, 2016.'),\n",
       " Document(metadata={'relevance_score': 0.0033634924}, page_content='84\\nEtl , O l AP and t rends\\nThe characteristics of MOLAP are:\\n y It is a user-friendly architecture, easy to use.\\n y The OLAP operations slice and dice speeds up the data retrieval.\\n y It has small pre-computed hypercubes.\\nTools that incorporate \\nMOLAP include Oracle Essbase, IBM Cognos, and Apache   \\nKylin.\\nHOLAP Architecture \\nIt defines Hybrid Online Analytical Processing. It is the hybrid of ROLAP and \\nMOLAP technologies. It connect both the dimensions together in one architecture. \\nIt stores the intermediate or part of the data in ROLAP and MOLAP. Depending on \\nthe query request it accesses the databases. It stores the relational tables in ROLAP \\nstructure, and the data requires multidimensional view are stored and processed \\nusing MOLAP architecture as shown in figure 12. It has the following components:\\n y Database server\\n y ROLAP and MOLAP server\\n y Front-end tool\\n \\nFigure 12 : HOLAP architecture( source: internet)\\nThe characteristics of HOLAP are:\\n y Flexible handling of data.\\n y Faster aggregation of data.\\n y HOLAP can \\ndrill down the hierarchy of data and can access to relational \\ndatabase for any relevant and stored information in it.\\nPopular HOLAP products are Microsoft SQL Server 2000 presents a hybrid OLAP \\nserver.\\nDOLAP Architecture \\nDesktop Online Analytical Processing (DOLAP) architecture is most suitable for \\nlocal multidimensional analysis. It is like a miniature of multidimensional database \\nor it’s like a sub cube or any business data cube. The components are:')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressor = CohereRerank(cohere_api_key=\"nbDqU1hTVxWmXGbLYI6OnYhp4Cx40MZ5hOmO5oKX\")\n",
    "     \n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    "    )\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "Introduction to Online \n",
      "Analytical Processing\n",
      "5.6  Data Warehouse and OLAP: Hypercube and Multi   \n",
      "Cubes\n",
      "The OLAP cube is a data structure optimized for very quick data analysis. The OLAP \n",
      "Cube consists of numeric facts called measures which are categorized by dimensions. \n",
      "OLAP Cube is also called the hypercube. So, we can say that multidimensional \n",
      "Databases can we see hypercube and multi cube. Multidimensional cubes have \n",
      "smaller multiple cubes and in hypercube it seems there is one cube as logically all \n",
      "the data seems to be as one unit of cube.  Hypercube have multiple same dimensions \n",
      "logically. The differences of Multi cube and Hyper cube are shown in Table 1 below:Table 1: Differences between Multi cube and Hyper cube\n",
      "Multi Cube Hyper Cube\n",
      "Metadata Each dimension can belong to \n",
      "many cubes\n",
      "Each dimension belongs to one \n",
      "cube only\n",
      "Dimension Not necessary all the dimensions \n",
      "should belong to some cube\n",
      "Every dimension owned by a \n",
      "hypercube\n",
      "Measure \n",
      "Computation\n",
      "Complex, data can be retrieved \n",
      "from the all the cubes\n",
      "Simple, as all the numerical \n",
      "facts are available at one place\n",
      "Multiple multicube system, if there are \n",
      "two rows in the DIMENSIONS \n",
      "rowset for which the \n",
      "DIMENSION_NAME value \n",
      "is the same (and the CUBE_\n",
      "NAME value is different), these \n",
      "two rows represent the same \n",
      "dimension. As, sub cubes are \n",
      "built from the same pool of \n",
      "available dimensions.\n",
      "in a multiple hypercube \n",
      "scenario, it is possible for two \n",
      "hypercubes to have a dimension \n",
      "of the same name, each of which \n",
      "has different characteristics. In \n",
      "this case, the DIMENSION_\n",
      "UNIQUE_NAME value is \n",
      "guaranteed to be different.\n",
      "5.7 APPLICATIONS OF OLAP\n",
      "OLAP reporting system is widely used in business applications like:\n",
      "•\t Sales\n",
      "\t\n",
      "and\n",
      "\t\n",
      "Marketing\n",
      "•\t Retail\n",
      "\t\n",
      "Industry\n",
      "•\t Financial\n",
      "\t\n",
      "Organizations\n",
      "\t\n",
      "–\n",
      "\t\n",
      "Budgeting\n",
      "•\t Agriculture\n",
      "•\t People\n",
      "\t\n",
      "Management\n",
      "•\t Process\n",
      "\t\n",
      "Management\n",
      "Examples are Essbase from Hyperion Solution and Express Server from Oracle.\n",
      " Check Your Progress 2\n",
      "1) Explain the OLAP application reporting system in Marketing?\n",
      " \n",
      "……………………………………………………………………………\n",
      "……………………………………………………………………………\n",
      "\n",
      "88\n",
      "Etl , O l AP and t rends\n",
      "Features ROLAP MOLAP HOLAP\n",
      "Storage space \n",
      "requirement\n",
      "Data is stored in \n",
      "relational tables. \n",
      "Comparatively \n",
      "Large storage \n",
      "space requirement \n",
      "Data is stored in \n",
      "multidimensional \n",
      "tables. Medium \n",
      "storage space \n",
      "requirements\n",
      "It uses both \n",
      "ROLAP, \n",
      "MOLAP. Small \n",
      "storage space \n",
      "requirements. No \n",
      "duplicate of data\n",
      "Latency Low latency High latency Medium latency \n",
      "Query response \n",
      "time\n",
      "Slow query \n",
      "response time \n",
      "Fast query \n",
      "response time.\n",
      "Medium query \n",
      "response time \n",
      "Volume of data Used for large \n",
      "volumes of data\n",
      "Limited volume of \n",
      "data\n",
      "Can be used in \n",
      "both scenarios\n",
      "Retreival of data Complex SQL \n",
      "queries are used\n",
      "Sparse Matrix is \n",
      "used\n",
      "Both\n",
      "Data View Static view of data Dynamic view of \n",
      "data\n",
      "Both static and \n",
      "dynamic view of \n",
      "data\n",
      "2)\n",
      " Limitations of OLA\n",
      "P cube are:\n",
      "\t •\t OLAP\n",
      "\t\n",
      "requires\n",
      "\t\n",
      "a\n",
      "\t\n",
      "star/snowflake\n",
      "\t\n",
      "schema:\n",
      "\t •\t \tThere\n",
      "\tis\n",
      "\ta\n",
      "\tlimited\n",
      "\tnumber\n",
      "\tof\n",
      "\tdimensions\n",
      "\t(fields)\n",
      "\ta\n",
      "\tsingle\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tIt\n",
      "\tis\n",
      "\tnearly\timpossible\n",
      "\tto\n",
      "\taccess\n",
      "\ttransactional\n",
      "\tdata\n",
      "\tin\n",
      "\tthe\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tChanges\n",
      "\tto\n",
      "\tan\n",
      "\tOLAP\n",
      "\tcube\n",
      "\trequires\n",
      "\ta\n",
      "\tfull\n",
      "\tupdate\n",
      "\tof\n",
      "\tthe\n",
      "\tcube\n",
      "\t–\n",
      "\ta\n",
      "\t\n",
      "lengthy process.\n",
      "5.13 FURTHER READINGS\n",
      " y William H. Inmon, Building the Data Warehouse, Wiley, 4th Edition, 2005.\n",
      " y Data Warehousing \n",
      "Fundamentals, Paulraj Ponnaiah, Wiley Student Edition \n",
      " y Data Warehousing, Reema Thareja, Oxford University Press\n",
      " y Data Warehousing, Data Mining & OLAP, Alex Berson and Stephen \n",
      "J.Smith,  Tata McGraw – Hill Edition, 2016.\n",
      "\n",
      "84\n",
      "Etl , O l AP and t rends\n",
      "The characteristics of MOLAP are:\n",
      " y It is a user-friendly architecture, easy to use.\n",
      " y The OLAP operations slice and dice speeds up the data retrieval.\n",
      " y It has small pre-computed hypercubes.\n",
      "Tools that incorporate \n",
      "MOLAP include Oracle Essbase, IBM Cognos, and Apache   \n",
      "Kylin.\n",
      "HOLAP Architecture \n",
      "It defines Hybrid Online Analytical Processing. It is the hybrid of ROLAP and \n",
      "MOLAP technologies. It connect both the dimensions together in one architecture. \n",
      "It stores the intermediate or part of the data in ROLAP and MOLAP. Depending on \n",
      "the query request it accesses the databases. It stores the relational tables in ROLAP \n",
      "structure, and the data requires multidimensional view are stored and processed \n",
      "using MOLAP architecture as shown in figure 12. It has the following components:\n",
      " y Database server\n",
      " y ROLAP and MOLAP server\n",
      " y Front-end tool\n",
      " \n",
      "Figure 12 : HOLAP architecture( source: internet)\n",
      "The characteristics of HOLAP are:\n",
      " y Flexible handling of data.\n",
      " y Faster aggregation of data.\n",
      " y HOLAP can \n",
      "drill down the hierarchy of data and can access to relational \n",
      "database for any relevant and stored information in it.\n",
      "Popular HOLAP products are Microsoft SQL Server 2000 presents a hybrid OLAP \n",
      "server.\n",
      "DOLAP Architecture \n",
      "Desktop Online Analytical Processing (DOLAP) architecture is most suitable for \n",
      "local multidimensional analysis. It is like a miniature of multidimensional database \n",
      "or it’s like a sub cube or any business data cube. The components are:\n"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
    "text_content = \"\\n\\n\".join(doc.page_content for doc in compressed_docs)\n",
    "print(text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]d:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub\\models--suriya7--Gemma2B-Finetuned-Sql-Generator. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 2 files: 100%|██████████| 2/2 [07:42<00:00, 231.13s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m model_answer\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Create database design assistant\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m assistant = \u001b[43mDatabaseDesignAssistant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Example use cases\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m1. E-commerce Platform Design:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mDatabaseDesignAssistant.__init__\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Set device\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda:0\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:573\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    572\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    577\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    579\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:272\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    274\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4455\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4445\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4446\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4448\u001b[39m     (\n\u001b[32m   4449\u001b[39m         model,\n\u001b[32m   4450\u001b[39m         missing_keys,\n\u001b[32m   4451\u001b[39m         unexpected_keys,\n\u001b[32m   4452\u001b[39m         mismatched_keys,\n\u001b[32m   4453\u001b[39m         offload_index,\n\u001b[32m   4454\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4455\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4461\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4465\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4475\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   4476\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4906\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, low_cpu_mem_usage, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, device_mesh, key_mapping, weights_only, _fast_init)\u001b[39m\n\u001b[32m   4904\u001b[39m         error_msgs += _load_state_dict_into_zero3_model(model_to_load, state_dict, assign_params)\n\u001b[32m   4905\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4906\u001b[39m         \u001b[43mmodel_to_load\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[43m=\u001b[49m\u001b[43massign_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[32m   4909\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2561\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2554\u001b[39m         out = hook(module, incompatible_keys)\n\u001b[32m   2555\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[32m   2556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mHooks registered with ``register_load_state_dict_post_hook`` are not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2557\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mexpected to return new values, if incompatible_keys need to be modified,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2558\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mit should be done inplace.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2559\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2561\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m load\n\u001b[32m   2564\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2549\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2543\u001b[39m         child_prefix = prefix + name + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2544\u001b[39m         child_state_dict = {\n\u001b[32m   2545\u001b[39m             k: v\n\u001b[32m   2546\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict.items()\n\u001b[32m   2547\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k.startswith(child_prefix)\n\u001b[32m   2548\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_prefix\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[32m   2552\u001b[39m incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2549\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2543\u001b[39m         child_prefix = prefix + name + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2544\u001b[39m         child_state_dict = {\n\u001b[32m   2545\u001b[39m             k: v\n\u001b[32m   2546\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict.items()\n\u001b[32m   2547\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k.startswith(child_prefix)\n\u001b[32m   2548\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_prefix\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[32m   2552\u001b[39m incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "    \u001b[31m[... skipping similar frames: Module.load_state_dict.<locals>.load at line 2549 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2549\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2543\u001b[39m         child_prefix = prefix + name + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2544\u001b[39m         child_state_dict = {\n\u001b[32m   2545\u001b[39m             k: v\n\u001b[32m   2546\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict.items()\n\u001b[32m   2547\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k.startswith(child_prefix)\n\u001b[32m   2548\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_prefix\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[32m   2552\u001b[39m incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2532\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m assign:\n\u001b[32m   2531\u001b[39m     local_metadata[\u001b[33m\"\u001b[39m\u001b[33massign_to_params_buffers\u001b[39m\u001b[33m\"\u001b[39m] = assign\n\u001b[32m-> \u001b[39m\u001b[32m2532\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module._modules.items():\n\u001b[32m   2542\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2438\u001b[39m, in \u001b[36mModule._load_from_state_dict\u001b[39m\u001b[34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[39m\n\u001b[32m   2436\u001b[39m             \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[32m   2437\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2438\u001b[39m             \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m   2440\u001b[39m     action = \u001b[33m\"\u001b[39m\u001b[33mswapping\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_swap_tensors \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcopying\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def generate_database_schema(user_query, olap_context, llm_res, client):\n",
    "    chat_completion = client.chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_database_schema(user_query, olap_context, llm_res, client):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                    The user has asked: '{user_query}'.\n",
    "                    Given the OLAP context: {olap_context}, and considering the following response: {llm_res}, \n",
    "                    generate a well-structured relational database schema having all possible tables related to it that includes:\n",
    "                    \n",
    "                    - Tables with their respective names\n",
    "                    - Columns with appropriate data types\n",
    "                    - Primary and foreign key constraints\n",
    "                    - Relationships between tables (one-to-one, one-to-many, many-to-many)\n",
    "\n",
    "                    \n",
    "                    Ensure the schema is optimized for analytical workloads and adheres to best database design practices.\n",
    "                \"\"\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        max_tokens=5000,\n",
    "    )\n",
    "\n",
    "    # Get response text\n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Clean up unnecessary formatting\n",
    "    cleaned_response = response_text.replace(\"\", \"\").replace(\"#\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "    # Return the cleaned schema\n",
    "    return cleaned_response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Online Retail Platform Database Schema**\n",
      "\n",
      "The following schema is designed to support analytical workloads and is optimized for query performance. It includes tables for sales, inventory, customer interactions, and other relevant data.\n",
      "\n",
      " Table: **Customers**\n",
      "sql\n",
      "CREATE TABLE Customers (\n",
      "  CustomerID INT PRIMARY KEY,\n",
      "  FirstName VARCHAR(50) NOT NULL,\n",
      "  LastName VARCHAR(50) NOT NULL,\n",
      "  Email VARCHAR(100) UNIQUE NOT NULL,\n",
      "  Phone VARCHAR(20),\n",
      "  Address VARCHAR(200)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Products**\n",
      "sql\n",
      "CREATE TABLE Products (\n",
      "  ProductID INT PRIMARY KEY,\n",
      "  ProductName VARCHAR(100) NOT NULL,\n",
      "  Description TEXT,\n",
      "  Price DECIMAL(10, 2) NOT NULL,\n",
      "  Category VARCHAR(50) NOT NULL,\n",
      "  Brand VARCHAR(50) NOT NULL\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Inventory**\n",
      "sql\n",
      "CREATE TABLE Inventory (\n",
      "  InventoryID INT PRIMARY KEY,\n",
      "  ProductID INT NOT NULL,\n",
      "  Quantity INT NOT NULL,\n",
      "  WarehouseLocation VARCHAR(100) NOT NULL,\n",
      "  FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Orders**\n",
      "sql\n",
      "CREATE TABLE Orders (\n",
      "  OrderID INT PRIMARY KEY,\n",
      "  CustomerID INT NOT NULL,\n",
      "  OrderDate DATE NOT NULL,\n",
      "  TotalAmount DECIMAL(10, 2) NOT NULL,\n",
      "  FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **OrderItems**\n",
      "sql\n",
      "CREATE TABLE OrderItems (\n",
      "  OrderItemID INT PRIMARY KEY,\n",
      "  OrderID INT NOT NULL,\n",
      "  ProductID INT NOT NULL,\n",
      "  Quantity INT NOT NULL,\n",
      "  UnitPrice DECIMAL(10, 2) NOT NULL,\n",
      "  FOREIGN KEY (OrderID) REFERENCES Orders(OrderID),\n",
      "  FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Sales**\n",
      "sql\n",
      "CREATE TABLE Sales (\n",
      "  SaleID INT PRIMARY KEY,\n",
      "  OrderID INT NOT NULL,\n",
      "  SaleDate DATE NOT NULL,\n",
      "  Amount DECIMAL(10, 2) NOT NULL,\n",
      "  FOREIGN KEY (OrderID) REFERENCES Orders(OrderID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **CustomerInteractions**\n",
      "sql\n",
      "CREATE TABLE CustomerInteractions (\n",
      "  InteractionID INT PRIMARY KEY,\n",
      "  CustomerID INT NOT NULL,\n",
      "  InteractionDate DATE NOT NULL,\n",
      "  InteractionType VARCHAR(50) NOT NULL,\n",
      "  InteractionDescription TEXT,\n",
      "  FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **DateDims**\n",
      "sql\n",
      "CREATE TABLE DateDims (\n",
      "  DateKey DATE PRIMARY KEY,\n",
      "  DateDescription VARCHAR(20) NOT NULL,\n",
      "  Year INT NOT NULL,\n",
      "  Quarter INT NOT NULL,\n",
      "  Month INT NOT NULL,\n",
      "  Day INT NOT NULL\n",
      ");\n",
      "\n",
      "\n",
      " Table: **ProductDims**\n",
      "sql\n",
      "CREATE TABLE ProductDims (\n",
      "  ProductKey INT PRIMARY KEY,\n",
      "  ProductID INT NOT NULL,\n",
      "  ProductCategory VARCHAR(50) NOT NULL,\n",
      "  ProductBrand VARCHAR(50) NOT NULL,\n",
      "  FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **SalesFact**\n",
      "sql\n",
      "CREATE TABLE SalesFact (\n",
      "  SaleID INT NOT NULL,\n",
      "  DateKey DATE NOT NULL,\n",
      "  ProductKey INT NOT NULL,\n",
      "  CustomerID INT NOT NULL,\n",
      "  SalesAmount DECIMAL(10, 2) NOT NULL,\n",
      "  PRIMARY KEY (SaleID, DateKey, ProductKey, CustomerID),\n",
      "  FOREIGN KEY (SaleID) REFERENCES Sales(SaleID),\n",
      "  FOREIGN KEY (DateKey) REFERENCES DateDims(DateKey),\n",
      "  FOREIGN KEY (ProductKey) REFERENCES ProductDims(ProductKey),\n",
      "  FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n",
      ");\n",
      "\n",
      "\n",
      " Relationships:\n",
      "\n",
      "* One customer can have many orders (one-to-many).\n",
      "* One order is associated with one customer (many-to-one).\n",
      "* One order can have many order items (one-to-many).\n",
      "* One order item is associated with one order (many-to-one).\n",
      "* One product can have many order items (one-to-many).\n",
      "* One order item is associated with one product (many-to-one).\n",
      "* One sale is associated with one order (many-to-one).\n",
      "* One customer interaction is associated with one customer (many-to-one).\n",
      "\n",
      " Indexing:\n",
      "\n",
      "* Create indexes on columns used in WHERE and JOIN clauses to improve query performance.\n",
      "* Use bitmap indexes for low-cardinality columns and B-tree indexes for high-cardinality columns.\n",
      "\n",
      " Partitioning:\n",
      "\n",
      "* Use range partitioning to divide large tables into smaller segments based on date or other criteria.\n",
      "* Use list partitioning to separate data into distinct categories.\n",
      "\n",
      " Views:\n",
      "\n",
      "* Create views to simplify complex queries and improve data accessibility.\n",
      "* Use materialized views to store pre-computed results and reduce query execution time.\n",
      "\n",
      "This schema is designed to support analytical workloads and is optimized for query performance. It includes tables for sales, inventory, customer interactions, and other relevant data, and establishes relationships between them to enable efficient querying and analysis.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "olap_context = \"\"\"\n",
    "It uses both\n",
    "ROLAP,\n",
    "MOLAP. Small\n",
    "storage space\n",
    "requirements. No\n",
    "duplicate of data\n",
    "Latency Low latency High latency Medium latency\n",
    "Query response\n",
    "time\n",
    "Slow query\n",
    "response time\n",
    "Fast query\n",
    "response time.\n",
    "Medium query\n",
    "response time\n",
    "Volume of data Used for large\n",
    "volumes of data\n",
    "Limited volume of\n",
    "data\n",
    "Can be used in\n",
    "both scenarios\n",
    "Retreival of data Complex SQL\n",
    "queries are used\n",
    "Sparse Matrix is\n",
    "used\n",
    "Both\n",
    "Data View Static view of data Dynamic view of\n",
    "data\n",
    "Both static and\n",
    "dynamic view of\n",
    "data\n",
    "2)\n",
    " Limitations of OLA\n",
    "P cube are:\n",
    "         •       OLAP\n",
    "\n",
    "requires\n",
    "\n",
    "a\n",
    "\n",
    "star/snowflake\n",
    "\n",
    "schema:\n",
    "         •              There\n",
    "        is\n",
    "        a\n",
    "        limited\n",
    "        number\n",
    "        of\n",
    "        dimensions\n",
    "        (fields)\n",
    "        a\n",
    "        single\n",
    "        OLAP\n",
    "\n",
    "cube.\n",
    "\n",
    "•               It\n",
    "        is\n",
    "        nearly  impossible\n",
    "        to\n",
    "        access\n",
    "        transactional\n",
    "        data\n",
    "        in\n",
    "        the\n",
    "        OLAP\n",
    "\n",
    "cube.\n",
    "\n",
    "•               Changes\n",
    "        to\n",
    "        an\n",
    "        OLAP\n",
    "        cube\n",
    "        requires\n",
    "        a\n",
    "        full\n",
    "        update\n",
    "        of\n",
    "        the\n",
    "        cube\n",
    "        –\n",
    "        a\n",
    "\"\"\"\n",
    "\n",
    "llm_res = \"\"\"\n",
    "Final Response:\n",
    " OLAP Best Practices for Large-Scale Analytical Workloads\n",
    "\n",
    " Data Modeling\n",
    "\n",
    "1. Star and Snowflake Schemas: Use star and snowflake schemas to optimize query performance by reducing the number of joins.\n",
    "2. Fact and Dimension Tables: Separate fact tables (e.g., sales, inventory) from dimension tables (e.g., date, customer, product) to improve data organization and query efficiency.\n",
    "3. Use Surrogate Keys: Employ surrogate keys to ensure data consistency and minimize data redundancy.\n",
    "\n",
    " Indexing\n",
    "\n",
    "1. Bitmap Indexes: Utilize bitmap indexes for low-cardinality columns to improve query performance.\n",
    "2. B-Tree Indexes: Use B-tree indexes for high-cardinality columns to optimize query performance.\n",
    "3. Composite Indexes: Create composite indexes on frequently used columns to reduce query execution time.\n",
    "\n",
    " Partitioning\n",
    "\n",
    "1. Range Partitioning: Use range partitioning to divide large fact tables into smaller, more manageable segments.\n",
    "2. List Partitioning: Employ list partitioning to separate data into distinct categories (e.g., by region or product category).\n",
    "3. Composite Partitioning: Combine range and list partitioning to further optimize query performance.\n",
    "\n",
    " Query Optimization\n",
    "\n",
    "1. Pre-Aggregation: Pre-aggregate data to reduce query execution time and improve performance.\n",
    "2. Materialized Views: Utilize materialized views to store pre-computed results and reduce query execution time.\n",
    "3. Query Rewriting: Rewrite queries to optimize performance by reducing the number of joins and subqueries.\n",
    "\n",
    " Performance Tuning\n",
    "\n",
    "1. Regular Maintenance: Regularly maintain the database by updating statistics, rebuilding indexes, and checking for data consistency.\n",
    "2. Monitor Performance: Monitor query performance and adjust optimization strategies as needed.\n",
    "3. Data Pruning: Prune unnecessary data to reduce storage costs and improve query performance.\n",
    "\n",
    " Additional Recommendations\n",
    "\n",
    "1. Use Column-Store Indexes: Use column-store indexes to optimize query performance for large-scale analytical workloads.\n",
    "2. Leverage Parallel Processing: Leverage parallel processing capabilities to improve query performance and reduce execution time.\n",
    "3. Implement Data Caching: Implement data caching mechanisms to reduce query execution time and improve performance.\n",
    "\n",
    "By following these OLAP best practices, you can optimize your database design and improve query performance for large-scale analytical workloads. This will enable you to make informed business decisions and drive growth for your online retail platform.\n",
    "\n",
    "Example OLAP Schema\n",
    "sql\n",
    "-- Fact table: sales\n",
    "CREATE TABLE sales (\n",
    "  sale_id INT,\n",
    "  date_key INT,\n",
    "  customer_key INT,\n",
    "  product_key INT,\n",
    "  sales_amount DECIMAL(10, 2)\n",
    ");\n",
    "\n",
    "-- Dimension table: date\n",
    "CREATE TABLE date (\n",
    "  date_key INT,\n",
    "  date_description VARCHAR(20)\n",
    ");\n",
    "\n",
    "-- Dimension table: customer\n",
    "CREATE TABLE customer (\n",
    "  customer_key INT,\n",
    "  customer_name VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- Dimension table: product\n",
    "CREATE TABLE product (\n",
    "  product_key INT,\n",
    "  product_name VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- Create star schema\n",
    "CREATE VIEW sales_star AS\n",
    "SELECT s.sale_id, s.date_key, s.customer_key, s.product_key, s.sales_amount,\n",
    "       d.date_description, c.customer_name, p.product_name\n",
    "FROM sales s\n",
    "JOIN date d ON s.date_key = d.date_key\n",
    "JOIN customer c ON s.customer_key = c.customer_key\n",
    "JOIN product p ON s.product_key = p.product_key;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"Design a database for an online retail platform tracking sales, inventory, and customer interactions\"\n",
    "ans = generate_database_schema(user_query,olap_context, llm_res, client)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = \"\"\" Tables\n",
    "\n",
    " 1. **Customers**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `customer_id` | `int` | Unique customer identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Customer name |\n",
    "| `email` | `varchar(255)` | Customer email |\n",
    "| `phone` | `varchar(20)` | Customer phone number |\n",
    "| `address` | `text` | Customer address |\n",
    "\n",
    " 2. **Products**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `product_id` | `int` | Unique product identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Product name |\n",
    "| `description` | `text` | Product description |\n",
    "| `price` | `decimal(10, 2)` | Product price |\n",
    "| `category_id` | `int` | Foreign key referencing the `Categories` table |\n",
    "\n",
    " 3. **Categories**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `category_id` | `int` | Unique category identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Category name |\n",
    "| `description` | `text` | Category description |\n",
    "\n",
    " 4. **Orders**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `order_id` | `int` | Unique order identifier (Primary Key) |\n",
    "| `customer_id` | `int` | Foreign key referencing the `Customers` table |\n",
    "| `order_date` | `date` | Order date |\n",
    "| `total` | `decimal(10, 2)` | Order total |\n",
    "\n",
    " 5. **Order Items**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `order_item_id` | `int` | Unique order item identifier (Primary Key) |\n",
    "| `order_id` | `int` | Foreign key referencing the `Orders` table |\n",
    "| `product_id` | `int` | Foreign key referencing the `Products` table |\n",
    "| `quantity` | `int` | Quantity of the product ordered |\n",
    "| `unit_price` | `decimal(10, 2)` | Unit price of the product |\n",
    "\n",
    " 6. **Inventory**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `product_id` | `int` | Foreign key referencing the `Products` table |\n",
    "| `quantity` | `int` | Current quantity in stock |\n",
    "| `warehouse_id` | `int` | Foreign key referencing the `Warehouses` table |\n",
    "\n",
    " 7. **Warehouses**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `warehouse_id` | `int` | Unique warehouse identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Warehouse name |\n",
    "| `address` | `text` | Warehouse address |\n",
    "\n",
    " 8. **Sales**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `sale_id` | `int` | Unique sale identifier (Primary Key) |\n",
    "| `order_id` | `int` | Foreign key referencing the `Orders` table |\n",
    "| `product_id` | `int` | Foreign key referencing the `Products` table |\n",
    "| `quantity` | `int` | Quantity sold |\n",
    "| `revenue` | `decimal(10, 2)` | Revenue generated from the sale |\n",
    "\n",
    " Relationships\n",
    "\n",
    "* A customer can place many orders (one-to-many).\n",
    "* An order is associated with one customer (many-to-one).\n",
    "* An order can have many order items (one-to-many).\n",
    "* An order item is associated with one order (many-to-one).\n",
    "* A product can be part of many order items (one-to-many).\n",
    "* An order item is associated with one product (many-to-one).\n",
    "* A product can have many sales (one-to-many).\n",
    "* A sale is associated with one product (many-to-one).\n",
    "* A warehouse can store many products (one-to-many).\n",
    "* A product can be stored in many warehouses (many-to-many).\n",
    "\n",
    " Indexes\n",
    "\n",
    "* Create indexes on the following columns:\n",
    "        + `Customers`: `name`, `email`, `phone`\n",
    "        + `Products`: `name`, `description`, `price`\n",
    "        + `Orders`: `order_date`, `total`\n",
    "        + `Order Items`: `quantity`, `unit_price`\n",
    "        + `Inventory`: `quantity`\n",
    "        + `Sales`: `quantity`, `revenue`\n",
    "\n",
    " Partitioning\n",
    "\n",
    "* Partition the `Orders` table by date (e.g., monthly).\n",
    "* Partition the `Sales` table by date (e.g., monthly).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = \"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\"\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name='llama-3.3-70b-versatile')\n",
    "response = llm.invoke(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_22224\\3882320351.py:9: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'raw_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Initialize the graph with credentials\u001b[39;00m\n\u001b[32m      9\u001b[39m graph = Neo4jGraph(\n\u001b[32m     10\u001b[39m     url=NEO4J_URI,\n\u001b[32m     11\u001b[39m     username=NEO4J_USERNAME,\n\u001b[32m     12\u001b[39m     password=NEO4J_PASSWORD\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m raw_document = [Document(page_content=\u001b[43mraw_documents\u001b[49m)]\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TokenTextSplitter\n\u001b[32m     16\u001b[39m text_splitter = TokenTextSplitter(chunk_size=\u001b[32m512\u001b[39m, chunk_overlap=\u001b[32m24\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'raw_documents' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.schema import Document\n",
    "# Set your credentials\n",
    "NEO4J_URI = \"neo4j+s://791ec29e.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"sqJloNfV2JhYBEwkLVutmmv4kuKwOEnajD2qDkUgyBU\"\n",
    "\n",
    "# Initialize the graph with credentials\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "raw_document = [Document(page_content=raw_documents)]\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(raw_document[:3])\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "print(graph_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "def showGraph(cypher: str = default_cypher):\n",
    "    # Define Neo4j credentials directly\n",
    "    NEO4J_URI = \"neo4j+s://791ec29e.databases.neo4j.io\"\n",
    "    NEO4J_USERNAME = \"neo4j\"\n",
    "    NEO4J_PASSWORD = \"sqJloNfV2JhYBEwkLVutmmv4kuKwOEnajD2qDkUgyBU\"\n",
    "\n",
    "    # Create a Neo4j session to run queries\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri=NEO4J_URI,\n",
    "        auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    )\n",
    "    session = driver.session()\n",
    "    \n",
    "    # Execute Cypher query and visualize results\n",
    "    widget = GraphWidget(graph=session.run(cypher).graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    display(widget)\n",
    "    \n",
    "    return widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec723a14e16433995f80fc7f9a453d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='650px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec723a14e16433995f80fc7f9a453d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='650px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
