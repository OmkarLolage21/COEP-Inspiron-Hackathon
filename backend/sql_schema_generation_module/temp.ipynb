{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "WeaviateStartUpError",
     "evalue": "Weaviate did not start up in 5 seconds. Either the Weaviate URL https://07g2uev0rwmp0dhmx39ivq.c0.asia-southeast1.gcp.weaviate.cloud is wrong or Weaviate did not start up in the interval given in 'startup_period'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\weaviate\\connect\\connection.py:639\u001b[39m, in \u001b[36mConnection.wait_for_weaviate\u001b[39m\u001b[34m(self, startup_period)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    637\u001b[39m     \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mready_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_request_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINIT_CHECK_TIMEOUT\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://07g2uev0rwmp0dhmx39ivq.c0.asia-southeast1.gcp.weaviate.cloud/v1/.well-known/ready",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mWeaviateStartUpError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      8\u001b[39m weaviate_api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mWEAVIATE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m HF_TOKEN = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mHF_TOKEN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m client = \u001b[43mweaviate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweaviate_url\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_client_secret\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweaviate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAuthApiKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweaviate_api_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m         \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX-HuggingFace-Api-Key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHF_TOKEN\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(client.is_ready())\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\weaviate\\client.py:150\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, url, auth_client_secret, timeout_config, proxies, trust_env, additional_headers, startup_period, embedded_options, additional_config)\u001b[39m\n\u001b[32m    147\u001b[39m config = Config() \u001b[38;5;28;01mif\u001b[39;00m additional_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m additional_config\n\u001b[32m    148\u001b[39m url, embedded_db = \u001b[38;5;28mself\u001b[39m.__parse_url_and_embedded_db(url, embedded_options)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28mself\u001b[39m._connection = \u001b[43mConnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_client_secret\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_client_secret\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_get_valid_timeout_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstartup_period\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartup_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedded_db\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedded_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrcp_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrpc_port_experimental\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnection_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnection_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m.classification = Classification(\u001b[38;5;28mself\u001b[39m._connection)\n\u001b[32m    163\u001b[39m \u001b[38;5;28mself\u001b[39m.schema = Schema(\u001b[38;5;28mself\u001b[39m._connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\weaviate\\connect\\connection.py:162\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, url, auth_client_secret, timeout_config, proxies, trust_env, additional_headers, startup_period, connection_config, embedded_db, grcp_port)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m startup_period \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     _check_positive_num(startup_period, \u001b[33m\"\u001b[39m\u001b[33mstartup_period\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m, include_zero=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait_for_weaviate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstartup_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28mself\u001b[39m._create_sessions(auth_client_secret)\n\u001b[32m    165\u001b[39m \u001b[38;5;28mself\u001b[39m._add_adapter_to_session(connection_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\weaviate\\connect\\connection.py:642\u001b[39m, in \u001b[36mConnection.wait_for_weaviate\u001b[39m\u001b[34m(self, startup_period)\u001b[39m\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (RequestsHTTPError, RequestsConnectionError, ReadTimeout) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateStartUpError(\n\u001b[32m    643\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeaviate did not start up in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstartup_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds. Either the Weaviate URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is wrong or Weaviate did not start up in the interval given in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mstartup_period\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    644\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m\n",
      "\u001b[31mWeaviateStartUpError\u001b[39m: Weaviate did not start up in 5 seconds. Either the Weaviate URL https://07g2uev0rwmp0dhmx39ivq.c0.asia-southeast1.gcp.weaviate.cloud is wrong or Weaviate did not start up in the interval given in 'startup_period'."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "# from weaviate.classes.init import Auth\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "weaviate_url = os.getenv(\"WEAVIATE_URL\") \n",
    "weaviate_api_key = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=weaviate_url , auth_client_secret=weaviate.AuthApiKey(weaviate_api_key),\n",
    "    additional_headers={\n",
    "         \"X-HuggingFace-Api-Key\": HF_TOKEN\n",
    "    },\n",
    ")\n",
    "\n",
    "print(client.is_ready())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': []}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client.schema.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'RAG',\n",
       "   'description': 'Documents for RAG',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-huggingface': {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "     'type': 'text',\n",
       "     'useCache': True,\n",
       "     'useGPU': False,\n",
       "     'vectorizeClassName': True,\n",
       "     'waitForModel': False}},\n",
       "   'multiTenancyConfig': {'autoTenantActivation': False,\n",
       "    'autoTenantCreation': False,\n",
       "    'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'The content of the paragraph',\n",
       "     'indexFilterable': True,\n",
       "     'indexRangeFilters': False,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-huggingface': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'asyncEnabled': False,\n",
       "    'deletionStrategy': 'NoAutomatedResolution',\n",
       "    'factor': 1},\n",
       "   'shardingConfig': {'actualCount': 1,\n",
       "    'actualVirtualCount': 128,\n",
       "    'desiredCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'function': 'murmur3',\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'virtualPerPhysical': 128},\n",
       "   'vectorIndexConfig': {'bq': {'enabled': False},\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'distance': 'cosine',\n",
       "    'dynamicEfFactor': 8,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfMin': 100,\n",
       "    'ef': -1,\n",
       "    'efConstruction': 128,\n",
       "    'filterStrategy': 'sweeping',\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'maxConnections': 32,\n",
       "    'multivector': {'aggregation': 'maxSim', 'enabled': False},\n",
       "    'pq': {'bitCompression': False,\n",
       "     'centroids': 256,\n",
       "     'enabled': False,\n",
       "     'encoder': {'distribution': 'log-normal', 'type': 'kmeans'},\n",
       "     'segments': 0,\n",
       "     'trainingLimit': 100000},\n",
       "    'skip': False,\n",
       "    'sq': {'enabled': False, 'rescoreLimit': 20, 'trainingLimit': 100000},\n",
       "    'vectorCacheMaxObjects': 1000000000000},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-huggingface'}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"RAG\",\n",
    "            \"description\": \"Documents for RAG\",\n",
    "            \"vectorizer\": \"text2vec-huggingface\",\n",
    "            \"moduleConfig\": {\"text2vec-huggingface\": {\"model\": \"sentence-transformers/all-MiniLM-L6-v2\", \"type\": \"text\"}},\n",
    "            \"properties\": [\n",
    "                {\n",
    "                    \"dataType\": [\"text\"],\n",
    "                    \"description\": \"The content of the paragraph\",\n",
    "                    \"moduleConfig\": {\n",
    "                        \"text2vec-huggingface\": {\n",
    "                            \"skip\": False,\n",
    "                            \"vectorizePropertyName\": False,\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"content\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "     \n",
    "\n",
    "client.schema.create(schema)\n",
    "     \n",
    "\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever\n",
    "     \n",
    "\n",
    "retriever = WeaviateHybridSearchRetriever(\n",
    "    alpha = 0.5,               # defaults to 0.5, which is equal weighting between keyword and semantic search\n",
    "    client = client,           # keyword arguments to pass to the Weaviate client\n",
    "    index_name = \"RAG\",  # The name of the index to use\n",
    "    text_key = \"content\",         # The name of the text key to use\n",
    "    attributes = [], # The attributes to return in the results\n",
    "    create_schema_if_missing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='UNIT 5 INTRODUCTION TO ONLINE ANALYTICAL  \\nPROCESSING\\nStructure         \\n5.0 Introduction \\n5.1 \\n Objectives \\n5.2 \\n OLAP and its Need\\n5.3 \\n Characteristics of O\\nLAP\\n5.4 \\n OLAP and Multidim\\nensional Analysis\\n 5.4.1\\n Multidimens\\nional Logical Data Modeling and its Users\\n 5.4.2\\n Multidimens\\nional Structure\\n 5.4.3\\n Multidimens\\nional Operations \\n \\n5.5 \\n OLAP Functions\\n5.6 \\n Data Warehouse an\\nd OLAP: Hypercube and Multicubes\\n5.7 \\n Applications of OL\\nAP\\n5.8 \\n Steps in the OLAP Creation Process\\n5.9 \\n Advantages of OLAP\\n5.10\\n OLAP Architecture\\ns - MOLAP, ROLAP, HOLAP, DOLAP \\n5.11\\n \\nSummary\\n \\n5.12\\n Solutions/Answers   \\n \\n5.13\\n Further Readings\\n \\n5.0 INTRODUCTION \\nIn the earlier unit you had studied about Extract, Transform and Loading (ETL) \\nof a Data Warehouse. Within the data science field, there are two types of data \\nprocessing systems: online analytical processing (OLAP) and online transaction \\nprocessing (OLTP). The main difference is that one uses data to gain valuable \\ninsights, while the other is purely operational. However, there are meaningful ways \\nto use both systems to solve data problems. OLAP is a system for performing multi-\\ndimensional analysis at high speeds on large volumes of data. Typically, this data \\nis from a data warehouse, data mart or some other centralized data store. OLAP is \\nideal for data mining, business intelligence and complex analytical calculations, \\nas well as business reporting functions like financial analysis, budgeting and sales \\nforecasting.\\nIn this unit we will focus on Online Analytical Processing (OLAP).\\n  \\n5.1 OBJECTIVES\\nAfter going through this unit, you should be able to:\\n y understand the purpose of a OLAP; \\n y describe the motivation and benefits of OLAP;\\n y discuss Multidimensional Modeling;\\n y describe various OLAP operations;'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content='72\\nEtl , O l AP and t rends\\n y list multi cube Applications and steps to create OLAP server, and\\n y discuss between various types of OLAP like MOLAP, ROLAP, DOLAP \\nand HOLAP.\\n5.2 OLAP AND ITS NEED\\nOnline Analytical Processing (OLAP) is the technology to analyze and process data \\nfrom multiple sources at the same time. It accesses the multiple databases at the \\nsame time. It is a software which helps the data analysts to collect data from different \\nperspective for developing effective business strategies. The query operations like \\ngroup, join or aggregation can be easily done with OLAP using pre-calculated or \\npre-aggregated data hence making it much faster than simple relational databases. \\nYou can understand OLAP as a multi cubic structure, which has many cubes, each \\ncube is pertaining to some database. The cubes are designed in such a way that \\ngenerates reports effectively and efficiently. \\nOLAP is the core component of the data warehouse implementation, providing \\nfast and flexible multi-dimensional data analysis for business intelligence (BI) and \\ndecision support applications. OLAP (for online analytical processing) is a software \\nused to perform high-speed, multivariate analysis of large amounts of data in data \\nwarehouses, data markets, or other unified and centralized data warehouses. The \\ndata is broken down for display, monitoring or analysis. For example, sales figures \\ncan be related to location (region, country, state/province, company), time (year, \\nmonth, week, day), product (clothing, male/female/child, brand, type), etc., but In \\na data warehouse, records are stored in tables, and each table can only sort data on \\ntwo of the dimensions at a time. Recording and reorganizing them into a multi-\\ndimensional format allows very fast processing and very in-depth analysis\\nThe primary objective of OLAP or data analysis is not just data processing .For \\ninstance, If a company might compare their sales in the month of January with the \\nmonth of February then compare those results with another location which may be \\nstored in a separate database. In this case, it needs a multi-view of database design \\nstoring all the data categories. Another example of Amazon, it analyzes purchases \\nmade by its customers to recommend the customers with a personalized home page \\nof products which are likely to be interested by them.  So, this is one of the good \\nexamples of OLAP systems. It creates a single platform for all type of business \\nanalytical means which includes planning budgeting forecasting and analysis the \\nmain benefit of OLAP is the consistency of information and calculations using \\nOLAP systems we can easily apply security restrictions on users and objects to \\ncomply with regulations and protect sensitive data. \\nOLAP assists managers in making decisions by giving multidimensional record \\nviews that are efficient to provide, hence enhancing their productivity. Due to the \\ninherent flexibility support provided by organized databases, OLAP functions \\nare self-contained. Through extensive control of analysis-capabilities, it permits \\nsimulation of business models and challenges.         \\nLet’s see the need to use OLAP to have better understanding of OLAP over \\nrelational databases:\\n1)\\n Efficient \\nand Effective methods to improve the sales of an Organization: \\nIn retail, having multiple products with different number of channels for \\nselling the product across the globe. OLAP makes it effective and efficient'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content='73\\nIntroduction to Online \\nAnalytical Processing\\nto search for a product in s different of a different region within a specified \\ntime period(like, excluding weekdays sales or just weekend sales or festival \\nduration sales very specific from a very large data distributed.)\\n2)  It \\nimproves the sales of a business. The data analysis power of OLAP \\nbrings  effective \\nresults in sales. It helps in identifying expenditures which \\nproduce a  high return of investments (ROI).\\nUsually, data operations and analysis are performed using the simple spreadsheet, \\nwhere data values are arranged in row and column format. This is ideal for two-\\ndimensional data. However, OLAP contains multidimensional data, with data \\nusually obtained from a different and unrelated source. Using a spreadsheet is \\nnot an optimal option. The cube can store and analyze multidimensional data in a \\nlogical and orderly manner.\\n5.3 CHARACTER ISITCS OF OLAP\\nThe main characteristics of OLAP are as follows:\\n•\\t Fast: OLAP act as bridge between Data Warehouse and front-end. Hence \\nhelps in the better accessibility of data yielding faster results.\\n•\\t Analysis: OLAP data analysis and computational measure and their results \\nare stored in separate data files. OLAP distinguishes better zero and missing \\nvalues. It should ignore missing value and performs the correct aggregate \\nvalues. OLAP facilitates interactive query handling and complex analysis \\nfor the users.\\n•\\t Shared: OLAP operations drill-down or roll-up, it navigates between \\nvarious dimensions in multidimensional cube making it effective and \\nefficient reporting system.\\n•\\t Multidimensional: OLAP has Multidimensional conceptual view and \\naccess of data to different users at different levels. The increasing number \\nof dimensions and report generation performance of the OLAP system does \\nnot significantly degrade.\\n•\\t Data and Information: OLAP has calculation power for complex queries \\nand data. It does data visualization using graphs and charts.\\n5.4  OLAP AND MULTIDIMENSION AL ANALYSIS\\nThe multi-dimensional data model stores data in the form of data cube. In a data \\nwarehouse. Generally, it supports two- or three-dimension cubes. It gives the data \\ndifferent views and perspectives. Practically in retail store the data is maintained \\nmonth wise, item wise, region wise thus involving many different dimensions.\\n5.4.1 Multidimensional Logical Data Modelin g and its Users\\nThe multidimensional data modeling provides: \\n•\\t Different\\n\\tviews\\n\\tand\\n\\tperspectives\\n\\tto\\n\\tthe\\n\\tdata\\tfrom\\n\\tdifferent\\n\\tangles.\\n\\tThe\\n\\t\\nbusiness users have a dime\\nnsional and logical view of the data in the data \\nwarehouse.\\n•\\t Multidimensional\\n\\tconceptual\\n\\tview:\\n\\tIt\\n\\tallows\\n\\tusers\\n\\tto\\n\\thave\\n\\ta\\n\\tdimensional\\n\\t\\nand logical view of the data.'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content=\"74\\nEtl , O l AP and t rends\\n•\\t Multidimensional \\tmodeling \\tcreates \\tenvironment \\tfor \\tmultiuser. \\tSince \\tthe \\t\\nOLAP \\ntechniques are shared, the OLAP and database operations, containing \\nretrieval, update, adequacy control, integrity, and security can be easily \\nperformed.\\n For example, \\nin the Figure 1, it is shown that the dimensions Time, Regions \\nand Products of a company can be logically saved in a cube. In Figure 2, \\nin the cross tabular form in every quarter, products quantity are shown. In \\nFigure 1, Products, Time and Regions these dimensions can be combined \\ninto cubes you can imagine what two dimensions would look like by using \\na spreadsheet metaphor with the time dimension as the columns and the \\nproducts dimension as the rows if we add data to this view such as units sold \\nthat would be a measure.   Measures can be any quantity such as revenue \\n/ expenses / unit’s / statistics or any text or numerical value if we consider \\nadding the third dimension regions then you can imagine each region being \\nrepresented as an additional spreadsheet this is how it works when you're \\nlimited to a two-dimensional spreadsheet. however, an OLAP cube can \\nrepresent all three dimensions as a single data set which allows users to \\nfluidly explore all the data from any perspective and despite its name a cube \\ncan hold many more than three dimensions so what's the value of using all \\nthat to illustrate this. \\n \\nFigure 1: Cube Representation \\nFigure 2: Measurable Data Shown \\nLet’s say that a manager is tracking sales units with three different spreadsheets \\nwith three different dimensions products quarters and regions from looking at these \\nspreadsheets. it appears that everything is equal as the manager of these stores would\"), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='75\\nIntroduction to Online \\nAnalytical Processing\\nprobably stock them with the same number of items for each product quarter and \\nregion. The manager of a store house makes very different decisions to generate a \\nreport with just one or two dimensions or by adding more dimensions and reveal more \\ndetail which would allow to make better decisions on managing the inventory of the \\nstores. Hence, you can view OLAP facilitates Business Oriented multidimensional \\ndata having lot of calculations. The data saved in multidimensional structure is very \\nsignificant in speed thought analysis to companies to take better decisions.  OLAP \\nprovides the flexibility of data retrieval to generate reports. \\n5.4.2 Multidimensional Structure\\nIn the multidimensional model, data are organized into multiple dimensions, \\nand each dimension contains multiple levels of abstraction defined by concept \\nhierarchies. This organization provides users with the flexibility to view data from \\ndifferent perspectives. The data has been organized into multiple dimensions and at \\neach level of dimension, contains multiple levels of abstraction defining the concept \\nhierarchy. It provides flexibility to view data from different angles. Likewise, as \\nexplained earlier the conceptual hierarchy of a product is:\\nDepartment\\n\\t\\n→\\n\\t\\nCategory\\n\\t\\n→\\n\\t\\nSubcategory→\\n\\t\\nBrand→\\n\\t\\nProduct\\nIt is important to identify the hierarchy from multi-dimensional cube in terms of \\nquery. Then we must look at the performance measure or on which attribute or \\ndimension the query is focused on. \\n5.4.3 Multidimensional Operations\\nOLAP provides a user-friendly environment for interactive data analysis. A number \\nof OLAP data cube operations exist to materialize different views of data, allowing \\ninteractive querying and analysis of the data.\\nThe most popular end user operations on dimensional data are:\\n1)\\n \\nRoll-up\\n2)\\n \\nDrill-down\\n3)\\n Slice and Dice\\n4)\\n Pivot (rotate) \\nIn daily life we come across operations where the manager is interested in knowing the \\naggregate of data from the concept hierarchy. It can use the concept hierarchy to roll the \\ndata up so for instance instead of a daily aggregated data we have monthly aggregate \\ndata and quarterly and then annual year. The concept hierarchy of Time dimension be: \\nConcept hierarchy of Time dimension\\nYear\\nQuarter\\nMonth\\nWeek\\nDaily\\nSo, to perform this operation, we can roll-up  and store the result. Also, it can \\nsubtotal those aggregated data. So, if the manager is interested in going down the'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='76\\nEtl , O l AP and t rends\\nconcept hierarchy or interested in the minute details to find out the driving attribute \\nresponsible for the increase or decrease of sales. For this OLAP operation drill \\ndown can be performed. \\n1)\\n \\nRoll-up: \\nThe roll-up operation (also called drill-up or aggregation operation) performs \\naggregation on a data cube, either by climbing up a concept hierarchy for a \\ndimension or by climbing down a concept hierarchy, i.e. dimension reduction. \\nIn the following example given at figure 3, it is shown a multidimensional cube \\ncontaining the products of a Home appliances home appliances like laptop, \\nfurniture, mobile and kitchen appliances. If the manager wants to view the sales of \\nall the products quarterly, the Roll-up operation can be performed on the categories. \\nIn this aggregation process, data is category hierarchy moves up from mobile to the \\nKitchen store. In the roll-up process at least one or more dimensions get reduced \\nlike category here.\\n \\nFigure 3: Roll-up on (Category from Home Appliances and Electronics)\\nIt is also known as consolidation. This operation summarizes the data along the \\ndimension.\\n2)\\n \\nDrill-down: \\nThe drill down operation (also called roll-down) is the reverse of roll up. It navigates \\nfrom less detailed data to more detailed data. It can be realized by either stepping \\ndown a concept hierarchy for a dimension or introducing additional dimensions.  \\nFigure 4: Drill down from Time to Months'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='77\\nIntroduction to Online \\nAnalytical Processing\\nYou will observe in the above example given at figure 4 a multidimensional cube \\ncontaining products and time. The Time dimension has been expanded from \\nQuarter\\n\\t\\n→Months\\n\\t\\nto\\n\\t\\nobserve\\n\\t\\nthe\\n\\t\\nsales\\n\\t\\nmonth-wise.\\n\\t\\nThis\\n\\t\\nis\\n\\t\\ncalled\\n\\t\\nin\\n\\t\\nDrill\\n\\t\\ndown.\\n3)\\n \\nSlice: \\nThis enables an analyst to take one level of information for display. It is another \\nOLAP operation to fetch the data. In this the query on one dimension is triggered in \\nthe database and a new sub cube is created. \\nFigure 5: Slice OLAP Operation\\nIn the above figure 5 it can be observed that slice operation is performed on “Time” \\ndimension and a new sub cube is created to retrieve the results.\\nSlice for Time = “Q1”\\n4)\\n \\nDice: \\nThis allows an analyst to select data from multiple dimensions to analyze. This \\nOLAP operation is just like the Projection relational query you have read in \\nRDBMS. In this technique you select two or more dimensions that results in the \\ncreation of a sub cube as shown in figure 6:\\nDice for (Category= “Laptop” or “Mobile”) and (Time = “Q1” or “Q2”) and (Stock \\n= “Amount” or “Sale Quantity”)\\nFigure 6: Dice OLAP Operation'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='78\\nEtl , O l AP and t rends\\n4) Pivot: \\nAnalysts can gain a new view of data by rotating the data axes of the cube. This \\nOLAP operation \\nfixes one attribute as a Pivot and rotate the cube to fetch the results. \\nLike inverting the spreadsheet it gives a different perspective. You can observe in \\nthe figure 7 that the presentation of the dimensions has been changed to impart a \\ndifferent perspective of the data cube for data analysis.\\nFigure 7: Pivot OLAP Operation\\n\\uf043  Check Your Progress 1\\n1) Who are the users o f the Multidimensional Data Modeling?\\n \\n……………………………………………………………………………\\n……………………………………………………………………………\\n……………………………………………………………………………..\\n2) \\n What are the five c\\nategories of decision support tool?\\n \\n……………………………………………………………………………\\n……………………………………………………………………………\\n……………………………………………………………………………...\\n5.5 OLAP Functions\\nOnline Analytical Processing (OLAP) functions can return the ranking and row \\nnumbering. It is very similar to the SQL aggregate functions, however, an aggregate \\nfunction return an atomic value. \\n•\\t The\\n\\tOLAP\\n\\tfunction\\treturns\\n\\ta\\n\\tscalar\\n\\tvalue\\n\\tof\\n\\ta\\n\\tquery.\\n\\tOLAP\\n\\tfunctions\\n\\tcan\\n\\t\\nbe performed at the individual row levels too.\\n•\\t\\nOLAP\\n\\tfunctions\\n\\tprovide\\n\\tdata\\n\\tmining\\n\\tfunction\\nalities\\n\\tand\\n\\tdata\\n\\tanalysis.\\n\\tThe\\n\\t\\ndetailed data analysis and values are supported with OLAP functions.\\n•\\t\\nThe\\n\\texhaustive\\n\\tand\\n\\tcomprehensive\\n\\tdata\\n\\tanaly\\nsis\\n\\tcan\\n\\tbe\\n\\tachieved\\n\\trow\\n\\twise\\n\\t\\nunlike \\nsimple SQL functions produces results in the form of reports like \\nWITH. OLAP runs on rows of the data warehouse.\\n•\\t OLAP\\n\\tfunctions\\n\\tuses\\n\\tSQL\\n\\tcommands\\n\\tlike\\n\\tINSERT/SELECT/\\n\\tPOPULATE\\n\\t\\non tables or Views.'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='79\\nIntroduction to Online \\nAnalytical Processing\\n5.6  Data Warehouse and OLAP: Hypercube and Multi   \\nCubes\\nThe OLAP cube is a data structure optimized for very quick data analysis. The OLAP \\nCube consists of numeric facts called measures which are categorized by dimensions. \\nOLAP Cube is also called the hypercube. So, we can say that multidimensional \\nDatabases can we see hypercube and multi cube. Multidimensional cubes have \\nsmaller multiple cubes and in hypercube it seems there is one cube as logically all \\nthe data seems to be as one unit of cube.  Hypercube have multiple same dimensions \\nlogically. The differences of Multi cube and Hyper cube are shown in Table 1 below:Table 1: Differences between Multi cube and Hyper cube\\nMulti Cube Hyper Cube\\nMetadata Each dimension can belong to \\nmany cubes\\nEach dimension belongs to one \\ncube only\\nDimension Not necessary all the dimensions \\nshould belong to some cube\\nEvery dimension owned by a \\nhypercube\\nMeasure \\nComputation\\nComplex, data can be retrieved \\nfrom the all the cubes\\nSimple, as all the numerical \\nfacts are available at one place\\nMultiple multicube system, if there are \\ntwo rows in the DIMENSIONS \\nrowset for which the \\nDIMENSION_NAME value \\nis the same (and the CUBE_\\nNAME value is different), these \\ntwo rows represent the same \\ndimension. As, sub cubes are \\nbuilt from the same pool of \\navailable dimensions.\\nin a multiple hypercube \\nscenario, it is possible for two \\nhypercubes to have a dimension \\nof the same name, each of which \\nhas different characteristics. In \\nthis case, the DIMENSION_\\nUNIQUE_NAME value is \\nguaranteed to be different.\\n5.7 APPLICATIONS OF OLAP\\nOLAP reporting system is widely used in business applications like:\\n•\\t Sales\\n\\t\\nand\\n\\t\\nMarketing\\n•\\t Retail\\n\\t\\nIndustry\\n•\\t Financial\\n\\t\\nOrganizations\\n\\t\\n–\\n\\t\\nBudgeting\\n•\\t Agriculture\\n•\\t People\\n\\t\\nManagement\\n•\\t Process\\n\\t\\nManagement\\nExamples are Essbase from Hyperion Solution and Express Server from Oracle.\\n\\uf043 Check Your Progress 2\\n1) Explain the OLAP application reporting system in Marketing?\\n \\n……………………………………………………………………………\\n……………………………………………………………………………'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='80\\nEtl , O l AP and t rends\\n……………………………………………………………………………..\\n2)\\n What is the purpose of hyper cube. Show \\nslice and dice operation on the \\nsub-cube/hypercube?\\n \\n……………………………………………………………………………\\n……………………………………………………………………………\\n……………………………………………………………………………..\\n3)\\n List the features of \\nan OLAP. \\n \\n……………………………………………………………………………\\n……………………………………………………………………………\\n……………………………………………………………………………..\\n5.8 STEPS IN THE OLAP CREATION\\nThe basic unit of OLAP is an OLAP cube. It is a data structure designed for better \\nand faster retrieval of results from the data analysis. OLAP cubes. It has dimensions \\nwith numeric facts. The data arrangement in rows and columns in multidimensional \\nis the logical view not the physical view. \\nThe steps involved in the creation of OLAP are as follows: \\nSteps to create an OLAP\\nStep 1: Extract data from variety of sources like text, excel sheets, multimedia \\nfiles, Online Transaction Processing data in flat files.\\nStep 2: Transformation and Standardization of data: Since, the data is distributed \\nand incompatible to each other. It involves the data preprocessing or cleaning part \\nwhere the semantics of databases are changed into a standard form. \\nStep 3: Loading of data: After all the database nomenclature have been followed \\nthen the data is loaded onto the OLAP server or OLAP multidimensional cube.\\nStep 4: Building of a Cube for data analysis: \\n y Select the dimensions means set of subsets of significant attributes. \\n \\n y Select the concept hierarchies.\\n y Populate the cube with the relevant data\\n y Select the numeric attribute to apply aggregate function.\\nStep 5: Report Generation\\nThe steps to create OLAP shown in the below figure 8:\\nFigure 8 : Steps to create OLAP Cube'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content='81\\nIntroduction to Online \\nAnalytical Processing\\n5.9 ADVANTAGE S OF OLAP\\nThe SQL functions like Group By, Aggregating functions are quite complex to \\noperate in relational databases as compared to multidimensional databases. OLAP \\ncan pre-compute the queries can save in sub cubes. The hypercubes also make the \\ncomputation task faster and saves time. OLAP has proved to an extremely scalable \\nand user – friendly method which is able to perfectly cater to its entire customer \\nneeds ranging from small to large companies. \\nSome listed benefits of using OLAP are as follows:\\n•\\t Data\\n\\t\\nProcessing\\n\\t\\nat\\n\\t\\na\\n\\t\\nfaster\\n\\t\\nspeed\\nThe speed of query execution has been tremendous since the use of OLAP \\ntechnology and is now counted as one of the primary benefits for it. This prevents \\nthe customers from spending a lot of time and money on heavy calculations and \\ncreating complex reports.\\n•\\t Accessibility\\nThe cube enables the various kinds of data like – transactional data from various \\nresources, information about every supplier and consumer, etc. all is saved in a \\nconcise one location which is easy to operate. \\n•\\t Concise\\n\\t\\nand\\n\\t\\nFine\\n\\t\\nData\\nOLAP works on the principle of combining multiple and similar records together, \\nwhich are saved in multiple tables forming a schema between them as a source of \\nconnection. Theses tables combine to form the cube to make the massive information \\nconcise and yet finely available to the user. Records can be elemental right down \\nto a single element by “drill down” and back to the cube by “drill up” operations.\\n•\\t Data\\n\\t\\nRepresentation\\n\\t\\nin\\n\\t\\nMulti-Dimension\\nOLAP cube is the center of all the data. Each element of the cube contains various \\nattributes and the number of processes performed on it. The cube axes are outlined \\nby the measure and dimension of the cube which is mostly three - dimensional \\nsystem. This allows the user to take the information from various slices of the cube. \\nA cube slice is a two – dimensional in nature which gives a clear image of the \\nknowledge trying to be represented.\\n•\\t Business\\n\\t\\nExpressions\\n\\t\\ncommonly\\n\\t\\nused\\nThe size of an OLAP cube consisting of data portrays the company’s economic and \\nfinancial conditions. The end user does not manipulate the database files; they deal \\nwith end processes like products, salesmen, employees, customers, etc. This gives a \\nreason to even user with less to zero technical background to use LAP technology.\\n•\\t Situational\\n\\t\\nScenarios\\nThe way the cube can cover almost all parts of a data item is through creating \\nvarious what – if situations; these what – if situations help in extraction of cube \\ninformation without tampering the original information on the cube. This feature of \\nOLAP technology is responsible for providing the customers the ability to update \\nthe values to look at the consequences brought in the cube’s situation. Through this \\nfeature business intelligence can deeply examine the possible factors of driving a \\nsituation in a company and prevent them if necessary.'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='82\\nEtl , O l AP and t rends\\n•\\t Easily \\tUnderstood\\tTechnology\\nMost of \\nthe users or customers working on OLAP technology come from a \\nbackground of less to minimum technology skills. They mostly do not need any \\nunique training to use this technology, which in return helps the company save \\nsome money. Moreover, OLAP technology providers provide their end users with \\nenough tutorial, documents and some start off technical assistance particularly in \\ncase of web – based OLAP operations. The end customers are given sessions to \\ncontinuously work with a group of technical experts so that they do not have to \\nsolve all the OLAP issues by themselves.\\n5.10  OLAP ARCHITECTURE: MOLAP, ROLAP, HOLAP \\nAND DOLAP\\nThere are types of OLAP architecture: ROLAP, MOLAP, HOLAP and others as \\nshown in the below figure 9. \\nFigure 9: Types of OLAP Architecture\\nROLAP Architecture\\nROLAP implies Relational OLAP, an application based on relational DBMSs. It \\nperforms dynamic multidimensional analysis of data stored in a relational database. \\nThe architecture is like three-tiered. It has three components viz. front end (User \\nInterface), ROLAP server (Metadata request processing engine) and the back end \\n(Database Server) as shown in the Figure 10.\\n y Database server\\n y ROLAP server\\n y Front-end tool\\nIn this three-t\\niered architecture the user submits the request and ROLAP engine \\nconverts the request into SQL and submits to the backend database. After the \\nprocessing of request the engine, it presents the resulting data into multidimensional \\nformat to make the task easier for the client to view it.'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content='83\\nIntroduction to Online \\nAnalytical Processing\\nFigure 10 : ROLAP Architechture\\nThe characteristics of ROLAP are: \\n y ROLAP utilizes the more processing time and disk space. \\n y ROLAP enables and supports larger user group in the distributed \\nenvironment.\\n y ROLAP processes complex queries utilizing the greater amounts of data. \\n  \\nPopular ROLAP products include Metacube by Stanford Technology Group, Red \\nBrick Warehouse by Red Brick Systems.\\nMOLAP Architecture\\nMOLAP it stands for Multidimensional Online Analytical Processing. It processes \\nthe data using the multidimensional cube using various combinations. Since, the \\ndata is stored in multidimensional structure the MOLAP engine uses the pre-\\ncomputed or pre-stored and stored. The architecture has three components:\\n y Database server\\n y MOLAP server\\n y Front-end tool\\nMOLAP \\nengine processes pre-compiled information. It has dynamic abilities to \\nperform aggregation of concept hierarchy. MOLAP is very useful in time-series \\ndata analysis and economic evaluation. MOLAP in shown in Figure 11.\\nFigure 11 : MOLAP Architechture (Source : internet)'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='84\\nEtl , O l AP and t rends\\nThe characteristics of MOLAP are:\\n y It is a user-friendly architecture, easy to use.\\n y The OLAP operations slice and dice speeds up the data retrieval.\\n y It has small pre-computed hypercubes.\\nTools that incorporate \\nMOLAP include Oracle Essbase, IBM Cognos, and Apache   \\nKylin.\\nHOLAP Architecture \\nIt defines Hybrid Online Analytical Processing. It is the hybrid of ROLAP and \\nMOLAP technologies. It connect both the dimensions together in one architecture. \\nIt stores the intermediate or part of the data in ROLAP and MOLAP. Depending on \\nthe query request it accesses the databases. It stores the relational tables in ROLAP \\nstructure, and the data requires multidimensional view are stored and processed \\nusing MOLAP architecture as shown in figure 12. It has the following components:\\n y Database server\\n y ROLAP and MOLAP server\\n y Front-end tool\\n \\nFigure 12 : HOLAP architecture( source: internet)\\nThe characteristics of HOLAP are:\\n y Flexible handling of data.\\n y Faster aggregation of data.\\n y HOLAP can \\ndrill down the hierarchy of data and can access to relational \\ndatabase for any relevant and stored information in it.\\nPopular HOLAP products are Microsoft SQL Server 2000 presents a hybrid OLAP \\nserver.\\nDOLAP Architecture \\nDesktop Online Analytical Processing (DOLAP) architecture is most suitable for \\nlocal multidimensional analysis. It is like a miniature of multidimensional database \\nor it’s like a sub cube or any business data cube. The components are:'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='85\\nIntroduction to Online \\nAnalytical Processing\\n y Database Server\\n y DOLAP server\\n y Front End\\nThe characteristics of DOLAP are:\\n y The \\nthree-tiered architecture is designed for low-end, standalone user like a \\nsmall shop owner in the locality. \\n y The \\ndata cube is locally stored in the system so, retrieval of results is faster. \\n y No load on the backend or at the server end.\\n y DOLAP is relatively cheaper to deploy.\\n\\uf043 Check Your Progress 3\\n1) Compare ROLAP, MOLAP and HOLAP.\\n \\n……………………………………………………………………………\\n……………………………………………………………………………\\n……………………………………………………………………………...\\n2)\\n Write limitations of\\n OLAP cube.\\n \\n……………………………………………………………………………\\n……………………………………………………………………………\\n……………………………………………………………………………...\\n5.11 SUMMARY\\nOLAP has proven to be an asset in the field of Business Intelligence as it helps in \\nrelieving the large amount of data handling along adding the cost benefits of working \\nwith this very technique. Furthermore, OLAP providers normally offer their clients \\nwith significant documentation, tutorials, and spark off technical assistance in terms \\nof web-primarily based totally OLAP clients. The customers are continuously loose \\nto deal with the group of tech experts while not having to control all the troubles \\ntied to the software program themselves. The concept hierarchies help to organize \\nthe dimensions into logical levels. The various OLAP operations help to extract \\ninformation across sub cubes. The creation of cube and types of OLAPs helps to \\nunderstand the architecture and usage of various applications of OLAP.\\n5.12 SOLUTIONS/ANSWERS\\nCheck Your Progress 1\\n1) Knowledge workers such as data analysts, business analysts, and Executives \\nare the users of OLAP.\\n2)\\n Decision making T\\nool features are:\\n\\t •\\t Report\\n\\t\\nGeneration\\n\\t •\\t Query\\n\\t\\nHandling\\n\\t •\\t EIS\\n\\t\\n(Executive\\n\\t\\nInformation\\n\\t\\nSystem)\\n\\t •\\t OLAP\\n\\t\\n(Online\\n\\t\\nAnalytical\\n\\t\\nProcessing)\\n\\t •\\t Data\\n\\t\\nMining'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}, page_content='86\\nEtl , O l AP and t rends\\nCheck Your Progress 2\\n1) In Marketing, OLAP can be used for various purposes as it helps like planning, \\nbudgeting, Financial marketing, sales data analysis and forecasting. The \\ncustomer experience is very important to all the companies. So, OLAP \\nworks very efficiently in analyzing the data of customers, market research \\nanalysis, cost-benefit analysis of any project considering all the dimensions.\\n There \\nare various OLAP tools available. The OLAP tool should have the \\nability to analyze large amounts of data, data analysis, fast response to the \\nqueries and data visualization. For example, IBM Cognos is a very powerful \\nOLAP marketing tool.\\n2)\\n Purpose of Hyperc\\nube in OLAP: The cube is basically used to represent \\ndata with some meaningful measure to compute. Hypercube logically has \\nall the data at one place as a single unit or spreadsheet which makes the \\ncomputation of queries faster. Each dimension logically belongs to one cube. \\nFor example, a multidimensional cube contains data of the cities of India, \\nProduct,\\n\\tSales\\n\\tand\\n\\tTime\\n\\twith\\n\\tconceptual\\n\\thierarchy\\n\\t(Delhi→2018→Sales).\\n\\t\\nAs, shown in below figures.\\nFigure 13: Multidimensional Cube \\nIn the cube given in the overview section, a sub-cube(hypercube) is selected with \\nthe following conditions\\nLocation = “Delhi” or “Kolkata” Time = “Q1” or “Q2” , Item = “Car” or “Bus”\\nFigure 14 : Hypercube or sub-cube'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='87\\nIntroduction to Online \\nAnalytical Processing\\nSlice is performed on the dimension Time = “Q1”.\\nFigure 15 : Slice on Hyper cube\\nIn the sub-cube ,pivot operation is performed.\\nFigure 16: Pivot operation\\n3) Features of OLAP are:\\n\\t\\n•\\t Conceptual \\t\\nmultidimensional\\n\\t\\nview\\n\\t •\\t Accessibility\\n\\t\\nof\\n\\t\\ndata\\n\\t •\\t Efficient\\n\\t\\nand\\n\\t\\nflexible\\n\\t\\nReporting\\n\\t\\nsystem\\n\\t •\\t Client/Server\\n\\t\\narchitecture\\n\\t •\\t Supports\\n\\t\\nunrestricted\\n\\t\\ndimensions\\n\\t\\nand\\n\\taggregation\\n\\t\\nlevels\\n\\t •\\t Uses\\n\\t\\ndynamic\\n\\t\\nsparse\\n\\t\\nmatrix\\n\\t\\nhandling\\n\\tfor\\n\\t\\nfaster\\n\\t\\nquery\\n\\t\\nresults\\n\\t •\\t Multiuser\\n\\t\\nsupport\\nCheck Your Progress 3\\n1) Comparative analys is between ROLAP, MOLAP and HOLAP\\nFeatures ROLAP MOLAP HOLAP\\nAccessibility \\nof data an and \\nProcessing time\\nVery slow because \\nof join operation \\nbetween tables. \\nThe data is \\nfetched from data \\nwarehouse.\\nFast because of \\nmultidimensional \\nstorage. The data \\nis fetched from \\nmultidimensional \\ndata cube.\\nFast'), Document(metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-08-03T16:08:03+05:30', 'moddate': '2023-08-03T16:08:53+05:30', 'source': 'data.pdf', 'total_pages': 18, 'page': 17, 'page_label': '18'}, page_content='88\\nEtl , O l AP and t rends\\nFeatures ROLAP MOLAP HOLAP\\nStorage space \\nrequirement\\nData is stored in \\nrelational tables. \\nComparatively \\nLarge storage \\nspace requirement \\nData is stored in \\nmultidimensional \\ntables. Medium \\nstorage space \\nrequirements\\nIt uses both \\nROLAP, \\nMOLAP. Small \\nstorage space \\nrequirements. No \\nduplicate of data\\nLatency Low latency High latency Medium latency \\nQuery response \\ntime\\nSlow query \\nresponse time \\nFast query \\nresponse time.\\nMedium query \\nresponse time \\nVolume of data Used for large \\nvolumes of data\\nLimited volume of \\ndata\\nCan be used in \\nboth scenarios\\nRetreival of data Complex SQL \\nqueries are used\\nSparse Matrix is \\nused\\nBoth\\nData View Static view of data Dynamic view of \\ndata\\nBoth static and \\ndynamic view of \\ndata\\n2)\\n Limitations of OLA\\nP cube are:\\n\\t •\\t OLAP\\n\\t\\nrequires\\n\\t\\na\\n\\t\\nstar/snowflake\\n\\t\\nschema:\\n\\t •\\t \\tThere\\n\\tis\\n\\ta\\n\\tlimited\\n\\tnumber\\n\\tof\\n\\tdimensions\\n\\t(fields)\\n\\ta\\n\\tsingle\\n\\tOLAP\\n\\t\\ncube.\\n\\t\\n•\\t \\tIt\\n\\tis\\n\\tnearly\\timpossible\\n\\tto\\n\\taccess\\n\\ttransactional\\n\\tdata\\n\\tin\\n\\tthe\\n\\tOLAP\\n\\t\\ncube.\\n\\t\\n•\\t \\tChanges\\n\\tto\\n\\tan\\n\\tOLAP\\n\\tcube\\n\\trequires\\n\\ta\\n\\tfull\\n\\tupdate\\n\\tof\\n\\tthe\\n\\tcube\\n\\t–\\n\\ta\\n\\t\\nlengthy process.\\n5.13 FURTHER READINGS\\n y William H. Inmon, Building the Data Warehouse, Wiley, 4th Edition, 2005.\\n y Data Warehousing \\nFundamentals, Paulraj Ponnaiah, Wiley Student Edition \\n y Data Warehousing, Reema Thareja, Oxford University Press\\n y Data Warehousing, Data Mining & OLAP, Alex Berson and Stephen \\nJ.Smith,  Tata McGraw – Hill Edition, 2016.')]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "     \n",
    "\n",
    "loader = PyPDFLoader(\"data.pdf\")\n",
    "docs = loader.load()\n",
    "print(docs)\n",
    "\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "     \n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "     \n",
    "\n",
    "# docs = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "print(len(docs))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['34b85dfa-aaf2-4056-b10f-3e4bbd9d1b83',\n",
       " 'f5831ab3-f60a-4d06-a358-b29ff9b6396a',\n",
       " '82f86943-df5a-4cdd-9472-881d79291e76',\n",
       " '459cfa5a-c961-4ec3-b824-02b456b14cf4',\n",
       " '6dfeb124-e42a-4b4c-84b0-92c21e652b90',\n",
       " '0f2b5b95-e332-4eed-b9dc-64e1836131fb',\n",
       " 'f2f30967-74a2-47c8-a591-82b7271f8489',\n",
       " '8389ce49-443f-4e9d-9775-4c7fdb452802',\n",
       " '719d1801-5421-490d-a0e8-14fd9befe39e',\n",
       " 'c40f15b3-3b41-4b7a-bf12-64bc595dd5a5',\n",
       " '06e838e1-2928-4a48-9e57-9e1958da8b59',\n",
       " 'db367324-f83d-4ebb-96fa-bcc0f79ae21a',\n",
       " '74d460f8-dc43-4971-b404-cdc4721f2b06',\n",
       " '22b98786-5ec4-4198-9588-1c06f91ca760',\n",
       " '6469b026-f0e2-4f0c-8e94-66c30090a91f',\n",
       " '4b4ea56c-c0ae-4fcd-9d4e-f788af807059',\n",
       " '260f7b4d-8051-4994-b048-d13820da4aef',\n",
       " '5bcb4952-c488-4fec-b189-5603abc91e20']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "Introduction to Online \n",
      "Analytical Processing\n",
      "5.9 ADVANTAGE S OF OLAP\n",
      "The SQL functions like Group By, Aggregating functions are quite complex to \n",
      "operate in relational databases as compared to multidimensional databases. OLAP \n",
      "can pre-compute the queries can save in sub cubes. The hypercubes also make the \n",
      "computation task faster and saves time. OLAP has proved to an extremely scalable \n",
      "and user – friendly method which is able to perfectly cater to its entire customer \n",
      "needs ranging from small to large companies. \n",
      "Some listed benefits of using OLAP are as follows:\n",
      "•\t Data\n",
      "\t\n",
      "Processing\n",
      "\t\n",
      "at\n",
      "\t\n",
      "a\n",
      "\t\n",
      "faster\n",
      "\t\n",
      "speed\n",
      "The speed of query execution has been tremendous since the use of OLAP \n",
      "technology and is now counted as one of the primary benefits for it. This prevents \n",
      "the customers from spending a lot of time and money on heavy calculations and \n",
      "creating complex reports.\n",
      "•\t Accessibility\n",
      "The cube enables the various kinds of data like – transactional data from various \n",
      "resources, information about every supplier and consumer, etc. all is saved in a \n",
      "concise one location which is easy to operate. \n",
      "•\t Concise\n",
      "\t\n",
      "and\n",
      "\t\n",
      "Fine\n",
      "\t\n",
      "Data\n",
      "OLAP works on the principle of combining multiple and similar records together, \n",
      "which are saved in multiple tables forming a schema between them as a source of \n",
      "connection. Theses tables combine to form the cube to make the massive information \n",
      "concise and yet finely available to the user. Records can be elemental right down \n",
      "to a single element by “drill down” and back to the cube by “drill up” operations.\n",
      "•\t Data\n",
      "\t\n",
      "Representation\n",
      "\t\n",
      "in\n",
      "\t\n",
      "Multi-Dimension\n",
      "OLAP cube is the center of all the data. Each element of the cube contains various \n",
      "attributes and the number of processes performed on it. The cube axes are outlined \n",
      "by the measure and dimension of the cube which is mostly three - dimensional \n",
      "system. This allows the user to take the information from various slices of the cube. \n",
      "A cube slice is a two – dimensional in nature which gives a clear image of the \n",
      "knowledge trying to be represented.\n",
      "•\t Business\n",
      "\t\n",
      "Expressions\n",
      "\t\n",
      "commonly\n",
      "\t\n",
      "used\n",
      "The size of an OLAP cube consisting of data portrays the company’s economic and \n",
      "financial conditions. The end user does not manipulate the database files; they deal \n",
      "with end processes like products, salesmen, employees, customers, etc. This gives a \n",
      "reason to even user with less to zero technical background to use LAP technology.\n",
      "•\t Situational\n",
      "\t\n",
      "Scenarios\n",
      "The way the cube can cover almost all parts of a data item is through creating \n",
      "various what – if situations; these what – if situations help in extraction of cube \n",
      "information without tampering the original information on the cube. This feature of \n",
      "OLAP technology is responsible for providing the customers the ability to update \n",
      "the values to look at the consequences brought in the cube’s situation. Through this \n",
      "feature business intelligence can deeply examine the possible factors of driving a \n",
      "situation in a company and prevent them if necessary.\n"
     ]
    }
   ],
   "source": [
    "print(retriever.invoke(\"what is the best OLAP practices for creating 3 4 tables ?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "Etl , O l AP and t rends\n",
      "Features ROLAP MOLAP HOLAP\n",
      "Storage space \n",
      "requirement\n",
      "Data is stored in \n",
      "relational tables. \n",
      "Comparatively \n",
      "Large storage \n",
      "space requirement \n",
      "Data is stored in \n",
      "multidimensional \n",
      "tables. Medium \n",
      "storage space \n",
      "requirements\n",
      "It uses both \n",
      "ROLAP, \n",
      "MOLAP. Small \n",
      "storage space \n",
      "requirements. No \n",
      "duplicate of data\n",
      "Latency Low latency High latency Medium latency \n",
      "Query response \n",
      "time\n",
      "Slow query \n",
      "response time \n",
      "Fast query \n",
      "response time.\n",
      "Medium query \n",
      "response time \n",
      "Volume of data Used for large \n",
      "volumes of data\n",
      "Limited volume of \n",
      "data\n",
      "Can be used in \n",
      "both scenarios\n",
      "Retreival of data Complex SQL \n",
      "queries are used\n",
      "Sparse Matrix is \n",
      "used\n",
      "Both\n",
      "Data View Static view of data Dynamic view of \n",
      "data\n",
      "Both static and \n",
      "dynamic view of \n",
      "data\n",
      "2)\n",
      " Limitations of OLA\n",
      "P cube are:\n",
      "\t •\t OLAP\n",
      "\t\n",
      "requires\n",
      "\t\n",
      "a\n",
      "\t\n",
      "star/snowflake\n",
      "\t\n",
      "schema:\n",
      "\t •\t \tThere\n",
      "\tis\n",
      "\ta\n",
      "\tlimited\n",
      "\tnumber\n",
      "\tof\n",
      "\tdimensions\n",
      "\t(fields)\n",
      "\ta\n",
      "\tsingle\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tIt\n",
      "\tis\n",
      "\tnearly\timpossible\n",
      "\tto\n",
      "\taccess\n",
      "\ttransactional\n",
      "\tdata\n",
      "\tin\n",
      "\tthe\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tChanges\n",
      "\tto\n",
      "\tan\n",
      "\tOLAP\n",
      "\tcube\n",
      "\trequires\n",
      "\ta\n",
      "\tfull\n",
      "\tupdate\n",
      "\tof\n",
      "\tthe\n",
      "\tcube\n",
      "\t–\n",
      "\ta\n",
      "\t\n",
      "lengthy process.\n",
      "5.13 FURTHER READINGS\n",
      " y William H. Inmon, Building the Data Warehouse, Wiley, 4th Edition, 2005.\n",
      " y Data Warehousing \n",
      "Fundamentals, Paulraj Ponnaiah, Wiley Student Edition \n",
      " y Data Warehousing, Reema Thareja, Oxford University Press\n",
      " y Data Warehousing, Data Mining & OLAP, Alex Berson and Stephen \n",
      "J.Smith,  Tata McGraw – Hill Edition, 2016.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize Groq client with API key\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Function to get OLAP best practices based on user query\n",
    "def get_olap_best_practices(user_query):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"The user has asked: '{user_query}'. Based on this, provide the best OLAP (Online Analytical Processing) practices. you should answer just related to OLAP and dont include any user query info just give best OLAP practices based on user query \"\n",
    "                           \"Consider data modeling, indexing, partitioning, query optimization, and performance tuning for large-scale analytical workloads.\",\n",
    "                           \n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "    )\n",
    "    \n",
    "    # Get response text\n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Clean up unnecessary formatting (removing ** and #)\n",
    "    cleaned_response = response_text.replace(\"**\", \"\").replace(\"#\", \"\").replace(\"```\",\"\")\n",
    "\n",
    "    return cleaned_response.strip() \n",
    "\n",
    "# Example user query\n",
    "user_query = \"Give me a database table schema for my student management system\"\n",
    "response = get_olap_best_practices(user_query)\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove problematic escape sequences and extra formatting.\"\"\"\n",
    "    text = text.replace(\"**\", \"\").replace(\"#\", \"\")  # Remove markdown formatting\n",
    "    text = text.replace(\"\\\\\", \"\")  # Remove unnecessary backslashes\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    return text\n",
    "\n",
    "# Use the function before invoking the retriever\n",
    "cleaned_response = clean_text(response)\n",
    "print(retriever.invoke(cleaned_response)[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'relevance_score': 0.12646118}, page_content='79\\nIntroduction to Online \\nAnalytical Processing\\n5.6  Data Warehouse and OLAP: Hypercube and Multi   \\nCubes\\nThe OLAP cube is a data structure optimized for very quick data analysis. The OLAP \\nCube consists of numeric facts called measures which are categorized by dimensions. \\nOLAP Cube is also called the hypercube. So, we can say that multidimensional \\nDatabases can we see hypercube and multi cube. Multidimensional cubes have \\nsmaller multiple cubes and in hypercube it seems there is one cube as logically all \\nthe data seems to be as one unit of cube.  Hypercube have multiple same dimensions \\nlogically. The differences of Multi cube and Hyper cube are shown in Table 1 below:Table 1: Differences between Multi cube and Hyper cube\\nMulti Cube Hyper Cube\\nMetadata Each dimension can belong to \\nmany cubes\\nEach dimension belongs to one \\ncube only\\nDimension Not necessary all the dimensions \\nshould belong to some cube\\nEvery dimension owned by a \\nhypercube\\nMeasure \\nComputation\\nComplex, data can be retrieved \\nfrom the all the cubes\\nSimple, as all the numerical \\nfacts are available at one place\\nMultiple multicube system, if there are \\ntwo rows in the DIMENSIONS \\nrowset for which the \\nDIMENSION_NAME value \\nis the same (and the CUBE_\\nNAME value is different), these \\ntwo rows represent the same \\ndimension. As, sub cubes are \\nbuilt from the same pool of \\navailable dimensions.\\nin a multiple hypercube \\nscenario, it is possible for two \\nhypercubes to have a dimension \\nof the same name, each of which \\nhas different characteristics. In \\nthis case, the DIMENSION_\\nUNIQUE_NAME value is \\nguaranteed to be different.\\n5.7 APPLICATIONS OF OLAP\\nOLAP reporting system is widely used in business applications like:\\n•\\t Sales\\n\\t\\nand\\n\\t\\nMarketing\\n•\\t Retail\\n\\t\\nIndustry\\n•\\t Financial\\n\\t\\nOrganizations\\n\\t\\n–\\n\\t\\nBudgeting\\n•\\t Agriculture\\n•\\t People\\n\\t\\nManagement\\n•\\t Process\\n\\t\\nManagement\\nExamples are Essbase from Hyperion Solution and Express Server from Oracle.\\n\\uf043 Check Your Progress 2\\n1) Explain the OLAP application reporting system in Marketing?\\n \\n……………………………………………………………………………\\n……………………………………………………………………………'),\n",
       " Document(metadata={'relevance_score': 0.027169233}, page_content='88\\nEtl , O l AP and t rends\\nFeatures ROLAP MOLAP HOLAP\\nStorage space \\nrequirement\\nData is stored in \\nrelational tables. \\nComparatively \\nLarge storage \\nspace requirement \\nData is stored in \\nmultidimensional \\ntables. Medium \\nstorage space \\nrequirements\\nIt uses both \\nROLAP, \\nMOLAP. Small \\nstorage space \\nrequirements. No \\nduplicate of data\\nLatency Low latency High latency Medium latency \\nQuery response \\ntime\\nSlow query \\nresponse time \\nFast query \\nresponse time.\\nMedium query \\nresponse time \\nVolume of data Used for large \\nvolumes of data\\nLimited volume of \\ndata\\nCan be used in \\nboth scenarios\\nRetreival of data Complex SQL \\nqueries are used\\nSparse Matrix is \\nused\\nBoth\\nData View Static view of data Dynamic view of \\ndata\\nBoth static and \\ndynamic view of \\ndata\\n2)\\n Limitations of OLA\\nP cube are:\\n\\t •\\t OLAP\\n\\t\\nrequires\\n\\t\\na\\n\\t\\nstar/snowflake\\n\\t\\nschema:\\n\\t •\\t \\tThere\\n\\tis\\n\\ta\\n\\tlimited\\n\\tnumber\\n\\tof\\n\\tdimensions\\n\\t(fields)\\n\\ta\\n\\tsingle\\n\\tOLAP\\n\\t\\ncube.\\n\\t\\n•\\t \\tIt\\n\\tis\\n\\tnearly\\timpossible\\n\\tto\\n\\taccess\\n\\ttransactional\\n\\tdata\\n\\tin\\n\\tthe\\n\\tOLAP\\n\\t\\ncube.\\n\\t\\n•\\t \\tChanges\\n\\tto\\n\\tan\\n\\tOLAP\\n\\tcube\\n\\trequires\\n\\ta\\n\\tfull\\n\\tupdate\\n\\tof\\n\\tthe\\n\\tcube\\n\\t–\\n\\ta\\n\\t\\nlengthy process.\\n5.13 FURTHER READINGS\\n y William H. Inmon, Building the Data Warehouse, Wiley, 4th Edition, 2005.\\n y Data Warehousing \\nFundamentals, Paulraj Ponnaiah, Wiley Student Edition \\n y Data Warehousing, Reema Thareja, Oxford University Press\\n y Data Warehousing, Data Mining & OLAP, Alex Berson and Stephen \\nJ.Smith,  Tata McGraw – Hill Edition, 2016.'),\n",
       " Document(metadata={'relevance_score': 0.0033634924}, page_content='84\\nEtl , O l AP and t rends\\nThe characteristics of MOLAP are:\\n y It is a user-friendly architecture, easy to use.\\n y The OLAP operations slice and dice speeds up the data retrieval.\\n y It has small pre-computed hypercubes.\\nTools that incorporate \\nMOLAP include Oracle Essbase, IBM Cognos, and Apache   \\nKylin.\\nHOLAP Architecture \\nIt defines Hybrid Online Analytical Processing. It is the hybrid of ROLAP and \\nMOLAP technologies. It connect both the dimensions together in one architecture. \\nIt stores the intermediate or part of the data in ROLAP and MOLAP. Depending on \\nthe query request it accesses the databases. It stores the relational tables in ROLAP \\nstructure, and the data requires multidimensional view are stored and processed \\nusing MOLAP architecture as shown in figure 12. It has the following components:\\n y Database server\\n y ROLAP and MOLAP server\\n y Front-end tool\\n \\nFigure 12 : HOLAP architecture( source: internet)\\nThe characteristics of HOLAP are:\\n y Flexible handling of data.\\n y Faster aggregation of data.\\n y HOLAP can \\ndrill down the hierarchy of data and can access to relational \\ndatabase for any relevant and stored information in it.\\nPopular HOLAP products are Microsoft SQL Server 2000 presents a hybrid OLAP \\nserver.\\nDOLAP Architecture \\nDesktop Online Analytical Processing (DOLAP) architecture is most suitable for \\nlocal multidimensional analysis. It is like a miniature of multidimensional database \\nor it’s like a sub cube or any business data cube. The components are:')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressor = CohereRerank(cohere_api_key=\"nbDqU1hTVxWmXGbLYI6OnYhp4Cx40MZ5hOmO5oKX\")\n",
    "     \n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    "    )\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "Introduction to Online \n",
      "Analytical Processing\n",
      "5.6  Data Warehouse and OLAP: Hypercube and Multi   \n",
      "Cubes\n",
      "The OLAP cube is a data structure optimized for very quick data analysis. The OLAP \n",
      "Cube consists of numeric facts called measures which are categorized by dimensions. \n",
      "OLAP Cube is also called the hypercube. So, we can say that multidimensional \n",
      "Databases can we see hypercube and multi cube. Multidimensional cubes have \n",
      "smaller multiple cubes and in hypercube it seems there is one cube as logically all \n",
      "the data seems to be as one unit of cube.  Hypercube have multiple same dimensions \n",
      "logically. The differences of Multi cube and Hyper cube are shown in Table 1 below:Table 1: Differences between Multi cube and Hyper cube\n",
      "Multi Cube Hyper Cube\n",
      "Metadata Each dimension can belong to \n",
      "many cubes\n",
      "Each dimension belongs to one \n",
      "cube only\n",
      "Dimension Not necessary all the dimensions \n",
      "should belong to some cube\n",
      "Every dimension owned by a \n",
      "hypercube\n",
      "Measure \n",
      "Computation\n",
      "Complex, data can be retrieved \n",
      "from the all the cubes\n",
      "Simple, as all the numerical \n",
      "facts are available at one place\n",
      "Multiple multicube system, if there are \n",
      "two rows in the DIMENSIONS \n",
      "rowset for which the \n",
      "DIMENSION_NAME value \n",
      "is the same (and the CUBE_\n",
      "NAME value is different), these \n",
      "two rows represent the same \n",
      "dimension. As, sub cubes are \n",
      "built from the same pool of \n",
      "available dimensions.\n",
      "in a multiple hypercube \n",
      "scenario, it is possible for two \n",
      "hypercubes to have a dimension \n",
      "of the same name, each of which \n",
      "has different characteristics. In \n",
      "this case, the DIMENSION_\n",
      "UNIQUE_NAME value is \n",
      "guaranteed to be different.\n",
      "5.7 APPLICATIONS OF OLAP\n",
      "OLAP reporting system is widely used in business applications like:\n",
      "•\t Sales\n",
      "\t\n",
      "and\n",
      "\t\n",
      "Marketing\n",
      "•\t Retail\n",
      "\t\n",
      "Industry\n",
      "•\t Financial\n",
      "\t\n",
      "Organizations\n",
      "\t\n",
      "–\n",
      "\t\n",
      "Budgeting\n",
      "•\t Agriculture\n",
      "•\t People\n",
      "\t\n",
      "Management\n",
      "•\t Process\n",
      "\t\n",
      "Management\n",
      "Examples are Essbase from Hyperion Solution and Express Server from Oracle.\n",
      " Check Your Progress 2\n",
      "1) Explain the OLAP application reporting system in Marketing?\n",
      " \n",
      "……………………………………………………………………………\n",
      "……………………………………………………………………………\n",
      "\n",
      "88\n",
      "Etl , O l AP and t rends\n",
      "Features ROLAP MOLAP HOLAP\n",
      "Storage space \n",
      "requirement\n",
      "Data is stored in \n",
      "relational tables. \n",
      "Comparatively \n",
      "Large storage \n",
      "space requirement \n",
      "Data is stored in \n",
      "multidimensional \n",
      "tables. Medium \n",
      "storage space \n",
      "requirements\n",
      "It uses both \n",
      "ROLAP, \n",
      "MOLAP. Small \n",
      "storage space \n",
      "requirements. No \n",
      "duplicate of data\n",
      "Latency Low latency High latency Medium latency \n",
      "Query response \n",
      "time\n",
      "Slow query \n",
      "response time \n",
      "Fast query \n",
      "response time.\n",
      "Medium query \n",
      "response time \n",
      "Volume of data Used for large \n",
      "volumes of data\n",
      "Limited volume of \n",
      "data\n",
      "Can be used in \n",
      "both scenarios\n",
      "Retreival of data Complex SQL \n",
      "queries are used\n",
      "Sparse Matrix is \n",
      "used\n",
      "Both\n",
      "Data View Static view of data Dynamic view of \n",
      "data\n",
      "Both static and \n",
      "dynamic view of \n",
      "data\n",
      "2)\n",
      " Limitations of OLA\n",
      "P cube are:\n",
      "\t •\t OLAP\n",
      "\t\n",
      "requires\n",
      "\t\n",
      "a\n",
      "\t\n",
      "star/snowflake\n",
      "\t\n",
      "schema:\n",
      "\t •\t \tThere\n",
      "\tis\n",
      "\ta\n",
      "\tlimited\n",
      "\tnumber\n",
      "\tof\n",
      "\tdimensions\n",
      "\t(fields)\n",
      "\ta\n",
      "\tsingle\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tIt\n",
      "\tis\n",
      "\tnearly\timpossible\n",
      "\tto\n",
      "\taccess\n",
      "\ttransactional\n",
      "\tdata\n",
      "\tin\n",
      "\tthe\n",
      "\tOLAP\n",
      "\t\n",
      "cube.\n",
      "\t\n",
      "•\t \tChanges\n",
      "\tto\n",
      "\tan\n",
      "\tOLAP\n",
      "\tcube\n",
      "\trequires\n",
      "\ta\n",
      "\tfull\n",
      "\tupdate\n",
      "\tof\n",
      "\tthe\n",
      "\tcube\n",
      "\t–\n",
      "\ta\n",
      "\t\n",
      "lengthy process.\n",
      "5.13 FURTHER READINGS\n",
      " y William H. Inmon, Building the Data Warehouse, Wiley, 4th Edition, 2005.\n",
      " y Data Warehousing \n",
      "Fundamentals, Paulraj Ponnaiah, Wiley Student Edition \n",
      " y Data Warehousing, Reema Thareja, Oxford University Press\n",
      " y Data Warehousing, Data Mining & OLAP, Alex Berson and Stephen \n",
      "J.Smith,  Tata McGraw – Hill Edition, 2016.\n",
      "\n",
      "84\n",
      "Etl , O l AP and t rends\n",
      "The characteristics of MOLAP are:\n",
      " y It is a user-friendly architecture, easy to use.\n",
      " y The OLAP operations slice and dice speeds up the data retrieval.\n",
      " y It has small pre-computed hypercubes.\n",
      "Tools that incorporate \n",
      "MOLAP include Oracle Essbase, IBM Cognos, and Apache   \n",
      "Kylin.\n",
      "HOLAP Architecture \n",
      "It defines Hybrid Online Analytical Processing. It is the hybrid of ROLAP and \n",
      "MOLAP technologies. It connect both the dimensions together in one architecture. \n",
      "It stores the intermediate or part of the data in ROLAP and MOLAP. Depending on \n",
      "the query request it accesses the databases. It stores the relational tables in ROLAP \n",
      "structure, and the data requires multidimensional view are stored and processed \n",
      "using MOLAP architecture as shown in figure 12. It has the following components:\n",
      " y Database server\n",
      " y ROLAP and MOLAP server\n",
      " y Front-end tool\n",
      " \n",
      "Figure 12 : HOLAP architecture( source: internet)\n",
      "The characteristics of HOLAP are:\n",
      " y Flexible handling of data.\n",
      " y Faster aggregation of data.\n",
      " y HOLAP can \n",
      "drill down the hierarchy of data and can access to relational \n",
      "database for any relevant and stored information in it.\n",
      "Popular HOLAP products are Microsoft SQL Server 2000 presents a hybrid OLAP \n",
      "server.\n",
      "DOLAP Architecture \n",
      "Desktop Online Analytical Processing (DOLAP) architecture is most suitable for \n",
      "local multidimensional analysis. It is like a miniature of multidimensional database \n",
      "or it’s like a sub cube or any business data cube. The components are:\n"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
    "text_content = \"\\n\\n\".join(doc.page_content for doc in compressed_docs)\n",
    "print(text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]d:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub\\models--suriya7--Gemma2B-Finetuned-Sql-Generator. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 2 files: 100%|██████████| 2/2 [07:42<00:00, 231.13s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m model_answer\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Create database design assistant\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m assistant = \u001b[43mDatabaseDesignAssistant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Example use cases\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m1. E-commerce Platform Design:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mDatabaseDesignAssistant.__init__\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Set device\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda:0\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:573\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    572\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    577\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    579\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:272\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    274\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4455\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4445\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4446\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4448\u001b[39m     (\n\u001b[32m   4449\u001b[39m         model,\n\u001b[32m   4450\u001b[39m         missing_keys,\n\u001b[32m   4451\u001b[39m         unexpected_keys,\n\u001b[32m   4452\u001b[39m         mismatched_keys,\n\u001b[32m   4453\u001b[39m         offload_index,\n\u001b[32m   4454\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4455\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4461\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4465\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4475\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   4476\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4906\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, low_cpu_mem_usage, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, device_mesh, key_mapping, weights_only, _fast_init)\u001b[39m\n\u001b[32m   4904\u001b[39m         error_msgs += _load_state_dict_into_zero3_model(model_to_load, state_dict, assign_params)\n\u001b[32m   4905\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4906\u001b[39m         \u001b[43mmodel_to_load\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign\u001b[49m\u001b[43m=\u001b[49m\u001b[43massign_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[32m   4909\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2561\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2554\u001b[39m         out = hook(module, incompatible_keys)\n\u001b[32m   2555\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[32m   2556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mHooks registered with ``register_load_state_dict_post_hook`` are not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2557\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mexpected to return new values, if incompatible_keys need to be modified,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2558\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mit should be done inplace.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2559\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2561\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m load\n\u001b[32m   2564\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2549\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2543\u001b[39m         child_prefix = prefix + name + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2544\u001b[39m         child_state_dict = {\n\u001b[32m   2545\u001b[39m             k: v\n\u001b[32m   2546\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict.items()\n\u001b[32m   2547\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k.startswith(child_prefix)\n\u001b[32m   2548\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_prefix\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[32m   2552\u001b[39m incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2549\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2543\u001b[39m         child_prefix = prefix + name + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2544\u001b[39m         child_state_dict = {\n\u001b[32m   2545\u001b[39m             k: v\n\u001b[32m   2546\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict.items()\n\u001b[32m   2547\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k.startswith(child_prefix)\n\u001b[32m   2548\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_prefix\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[32m   2552\u001b[39m incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "    \u001b[31m[... skipping similar frames: Module.load_state_dict.<locals>.load at line 2549 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2549\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2543\u001b[39m         child_prefix = prefix + name + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2544\u001b[39m         child_state_dict = {\n\u001b[32m   2545\u001b[39m             k: v\n\u001b[32m   2546\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict.items()\n\u001b[32m   2547\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k.startswith(child_prefix)\n\u001b[32m   2548\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_prefix\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[32m   2552\u001b[39m incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2532\u001b[39m, in \u001b[36mModule.load_state_dict.<locals>.load\u001b[39m\u001b[34m(module, local_state_dict, prefix)\u001b[39m\n\u001b[32m   2530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m assign:\n\u001b[32m   2531\u001b[39m     local_metadata[\u001b[33m\"\u001b[39m\u001b[33massign_to_params_buffers\u001b[39m\u001b[33m\"\u001b[39m] = assign\n\u001b[32m-> \u001b[39m\u001b[32m2532\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module._modules.items():\n\u001b[32m   2542\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodingStuff\\COEP-Inspiron-Hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2438\u001b[39m, in \u001b[36mModule._load_from_state_dict\u001b[39m\u001b[34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[39m\n\u001b[32m   2436\u001b[39m             \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[32m   2437\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2438\u001b[39m             \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m   2440\u001b[39m     action = \u001b[33m\"\u001b[39m\u001b[33mswapping\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_swap_tensors \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcopying\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def generate_database_schema(user_query, olap_context, llm_res, client):\n",
    "    chat_completion = client.chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_database_schema(user_query, olap_context, llm_res, client):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                    The user has asked: '{user_query}'.\n",
    "                    Given the OLAP context: {olap_context}, and considering the following response: {llm_res}, \n",
    "                    generate a well-structured relational database schema having all possible tables related to it that includes:\n",
    "                    \n",
    "                    - Tables with their respective names\n",
    "                    - Columns with appropriate data types\n",
    "                    - Primary and foreign key constraints\n",
    "                    - Relationships between tables (one-to-one, one-to-many, many-to-many)\n",
    "\n",
    "                    \n",
    "                    Ensure the schema is optimized for analytical workloads and adheres to best database design practices.\n",
    "                \"\"\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        max_tokens=5000,\n",
    "    )\n",
    "\n",
    "    # Get response text\n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Clean up unnecessary formatting\n",
    "    cleaned_response = response_text.replace(\"\", \"\").replace(\"#\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "    # Return the cleaned schema\n",
    "    return cleaned_response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Online Retail Platform Database Schema**\n",
      "\n",
      "The following schema is designed to support analytical workloads and is optimized for query performance. It includes tables for sales, inventory, customer interactions, and other relevant data.\n",
      "\n",
      " Table: **Customers**\n",
      "sql\n",
      "CREATE TABLE Customers (\n",
      "  CustomerID INT PRIMARY KEY,\n",
      "  FirstName VARCHAR(50) NOT NULL,\n",
      "  LastName VARCHAR(50) NOT NULL,\n",
      "  Email VARCHAR(100) UNIQUE NOT NULL,\n",
      "  Phone VARCHAR(20),\n",
      "  Address VARCHAR(200)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Products**\n",
      "sql\n",
      "CREATE TABLE Products (\n",
      "  ProductID INT PRIMARY KEY,\n",
      "  ProductName VARCHAR(100) NOT NULL,\n",
      "  Description TEXT,\n",
      "  Price DECIMAL(10, 2) NOT NULL,\n",
      "  Category VARCHAR(50) NOT NULL,\n",
      "  Brand VARCHAR(50) NOT NULL\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Inventory**\n",
      "sql\n",
      "CREATE TABLE Inventory (\n",
      "  InventoryID INT PRIMARY KEY,\n",
      "  ProductID INT NOT NULL,\n",
      "  Quantity INT NOT NULL,\n",
      "  WarehouseLocation VARCHAR(100) NOT NULL,\n",
      "  FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Orders**\n",
      "sql\n",
      "CREATE TABLE Orders (\n",
      "  OrderID INT PRIMARY KEY,\n",
      "  CustomerID INT NOT NULL,\n",
      "  OrderDate DATE NOT NULL,\n",
      "  TotalAmount DECIMAL(10, 2) NOT NULL,\n",
      "  FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **OrderItems**\n",
      "sql\n",
      "CREATE TABLE OrderItems (\n",
      "  OrderItemID INT PRIMARY KEY,\n",
      "  OrderID INT NOT NULL,\n",
      "  ProductID INT NOT NULL,\n",
      "  Quantity INT NOT NULL,\n",
      "  UnitPrice DECIMAL(10, 2) NOT NULL,\n",
      "  FOREIGN KEY (OrderID) REFERENCES Orders(OrderID),\n",
      "  FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **Sales**\n",
      "sql\n",
      "CREATE TABLE Sales (\n",
      "  SaleID INT PRIMARY KEY,\n",
      "  OrderID INT NOT NULL,\n",
      "  SaleDate DATE NOT NULL,\n",
      "  Amount DECIMAL(10, 2) NOT NULL,\n",
      "  FOREIGN KEY (OrderID) REFERENCES Orders(OrderID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **CustomerInteractions**\n",
      "sql\n",
      "CREATE TABLE CustomerInteractions (\n",
      "  InteractionID INT PRIMARY KEY,\n",
      "  CustomerID INT NOT NULL,\n",
      "  InteractionDate DATE NOT NULL,\n",
      "  InteractionType VARCHAR(50) NOT NULL,\n",
      "  InteractionDescription TEXT,\n",
      "  FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **DateDims**\n",
      "sql\n",
      "CREATE TABLE DateDims (\n",
      "  DateKey DATE PRIMARY KEY,\n",
      "  DateDescription VARCHAR(20) NOT NULL,\n",
      "  Year INT NOT NULL,\n",
      "  Quarter INT NOT NULL,\n",
      "  Month INT NOT NULL,\n",
      "  Day INT NOT NULL\n",
      ");\n",
      "\n",
      "\n",
      " Table: **ProductDims**\n",
      "sql\n",
      "CREATE TABLE ProductDims (\n",
      "  ProductKey INT PRIMARY KEY,\n",
      "  ProductID INT NOT NULL,\n",
      "  ProductCategory VARCHAR(50) NOT NULL,\n",
      "  ProductBrand VARCHAR(50) NOT NULL,\n",
      "  FOREIGN KEY (ProductID) REFERENCES Products(ProductID)\n",
      ");\n",
      "\n",
      "\n",
      " Table: **SalesFact**\n",
      "sql\n",
      "CREATE TABLE SalesFact (\n",
      "  SaleID INT NOT NULL,\n",
      "  DateKey DATE NOT NULL,\n",
      "  ProductKey INT NOT NULL,\n",
      "  CustomerID INT NOT NULL,\n",
      "  SalesAmount DECIMAL(10, 2) NOT NULL,\n",
      "  PRIMARY KEY (SaleID, DateKey, ProductKey, CustomerID),\n",
      "  FOREIGN KEY (SaleID) REFERENCES Sales(SaleID),\n",
      "  FOREIGN KEY (DateKey) REFERENCES DateDims(DateKey),\n",
      "  FOREIGN KEY (ProductKey) REFERENCES ProductDims(ProductKey),\n",
      "  FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\n",
      ");\n",
      "\n",
      "\n",
      " Relationships:\n",
      "\n",
      "* One customer can have many orders (one-to-many).\n",
      "* One order is associated with one customer (many-to-one).\n",
      "* One order can have many order items (one-to-many).\n",
      "* One order item is associated with one order (many-to-one).\n",
      "* One product can have many order items (one-to-many).\n",
      "* One order item is associated with one product (many-to-one).\n",
      "* One sale is associated with one order (many-to-one).\n",
      "* One customer interaction is associated with one customer (many-to-one).\n",
      "\n",
      " Indexing:\n",
      "\n",
      "* Create indexes on columns used in WHERE and JOIN clauses to improve query performance.\n",
      "* Use bitmap indexes for low-cardinality columns and B-tree indexes for high-cardinality columns.\n",
      "\n",
      " Partitioning:\n",
      "\n",
      "* Use range partitioning to divide large tables into smaller segments based on date or other criteria.\n",
      "* Use list partitioning to separate data into distinct categories.\n",
      "\n",
      " Views:\n",
      "\n",
      "* Create views to simplify complex queries and improve data accessibility.\n",
      "* Use materialized views to store pre-computed results and reduce query execution time.\n",
      "\n",
      "This schema is designed to support analytical workloads and is optimized for query performance. It includes tables for sales, inventory, customer interactions, and other relevant data, and establishes relationships between them to enable efficient querying and analysis.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "olap_context = \"\"\"\n",
    "It uses both\n",
    "ROLAP,\n",
    "MOLAP. Small\n",
    "storage space\n",
    "requirements. No\n",
    "duplicate of data\n",
    "Latency Low latency High latency Medium latency\n",
    "Query response\n",
    "time\n",
    "Slow query\n",
    "response time\n",
    "Fast query\n",
    "response time.\n",
    "Medium query\n",
    "response time\n",
    "Volume of data Used for large\n",
    "volumes of data\n",
    "Limited volume of\n",
    "data\n",
    "Can be used in\n",
    "both scenarios\n",
    "Retreival of data Complex SQL\n",
    "queries are used\n",
    "Sparse Matrix is\n",
    "used\n",
    "Both\n",
    "Data View Static view of data Dynamic view of\n",
    "data\n",
    "Both static and\n",
    "dynamic view of\n",
    "data\n",
    "2)\n",
    " Limitations of OLA\n",
    "P cube are:\n",
    "         •       OLAP\n",
    "\n",
    "requires\n",
    "\n",
    "a\n",
    "\n",
    "star/snowflake\n",
    "\n",
    "schema:\n",
    "         •              There\n",
    "        is\n",
    "        a\n",
    "        limited\n",
    "        number\n",
    "        of\n",
    "        dimensions\n",
    "        (fields)\n",
    "        a\n",
    "        single\n",
    "        OLAP\n",
    "\n",
    "cube.\n",
    "\n",
    "•               It\n",
    "        is\n",
    "        nearly  impossible\n",
    "        to\n",
    "        access\n",
    "        transactional\n",
    "        data\n",
    "        in\n",
    "        the\n",
    "        OLAP\n",
    "\n",
    "cube.\n",
    "\n",
    "•               Changes\n",
    "        to\n",
    "        an\n",
    "        OLAP\n",
    "        cube\n",
    "        requires\n",
    "        a\n",
    "        full\n",
    "        update\n",
    "        of\n",
    "        the\n",
    "        cube\n",
    "        –\n",
    "        a\n",
    "\"\"\"\n",
    "\n",
    "llm_res = \"\"\"\n",
    "Final Response:\n",
    " OLAP Best Practices for Large-Scale Analytical Workloads\n",
    "\n",
    " Data Modeling\n",
    "\n",
    "1. Star and Snowflake Schemas: Use star and snowflake schemas to optimize query performance by reducing the number of joins.\n",
    "2. Fact and Dimension Tables: Separate fact tables (e.g., sales, inventory) from dimension tables (e.g., date, customer, product) to improve data organization and query efficiency.\n",
    "3. Use Surrogate Keys: Employ surrogate keys to ensure data consistency and minimize data redundancy.\n",
    "\n",
    " Indexing\n",
    "\n",
    "1. Bitmap Indexes: Utilize bitmap indexes for low-cardinality columns to improve query performance.\n",
    "2. B-Tree Indexes: Use B-tree indexes for high-cardinality columns to optimize query performance.\n",
    "3. Composite Indexes: Create composite indexes on frequently used columns to reduce query execution time.\n",
    "\n",
    " Partitioning\n",
    "\n",
    "1. Range Partitioning: Use range partitioning to divide large fact tables into smaller, more manageable segments.\n",
    "2. List Partitioning: Employ list partitioning to separate data into distinct categories (e.g., by region or product category).\n",
    "3. Composite Partitioning: Combine range and list partitioning to further optimize query performance.\n",
    "\n",
    " Query Optimization\n",
    "\n",
    "1. Pre-Aggregation: Pre-aggregate data to reduce query execution time and improve performance.\n",
    "2. Materialized Views: Utilize materialized views to store pre-computed results and reduce query execution time.\n",
    "3. Query Rewriting: Rewrite queries to optimize performance by reducing the number of joins and subqueries.\n",
    "\n",
    " Performance Tuning\n",
    "\n",
    "1. Regular Maintenance: Regularly maintain the database by updating statistics, rebuilding indexes, and checking for data consistency.\n",
    "2. Monitor Performance: Monitor query performance and adjust optimization strategies as needed.\n",
    "3. Data Pruning: Prune unnecessary data to reduce storage costs and improve query performance.\n",
    "\n",
    " Additional Recommendations\n",
    "\n",
    "1. Use Column-Store Indexes: Use column-store indexes to optimize query performance for large-scale analytical workloads.\n",
    "2. Leverage Parallel Processing: Leverage parallel processing capabilities to improve query performance and reduce execution time.\n",
    "3. Implement Data Caching: Implement data caching mechanisms to reduce query execution time and improve performance.\n",
    "\n",
    "By following these OLAP best practices, you can optimize your database design and improve query performance for large-scale analytical workloads. This will enable you to make informed business decisions and drive growth for your online retail platform.\n",
    "\n",
    "Example OLAP Schema\n",
    "sql\n",
    "-- Fact table: sales\n",
    "CREATE TABLE sales (\n",
    "  sale_id INT,\n",
    "  date_key INT,\n",
    "  customer_key INT,\n",
    "  product_key INT,\n",
    "  sales_amount DECIMAL(10, 2)\n",
    ");\n",
    "\n",
    "-- Dimension table: date\n",
    "CREATE TABLE date (\n",
    "  date_key INT,\n",
    "  date_description VARCHAR(20)\n",
    ");\n",
    "\n",
    "-- Dimension table: customer\n",
    "CREATE TABLE customer (\n",
    "  customer_key INT,\n",
    "  customer_name VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- Dimension table: product\n",
    "CREATE TABLE product (\n",
    "  product_key INT,\n",
    "  product_name VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- Create star schema\n",
    "CREATE VIEW sales_star AS\n",
    "SELECT s.sale_id, s.date_key, s.customer_key, s.product_key, s.sales_amount,\n",
    "       d.date_description, c.customer_name, p.product_name\n",
    "FROM sales s\n",
    "JOIN date d ON s.date_key = d.date_key\n",
    "JOIN customer c ON s.customer_key = c.customer_key\n",
    "JOIN product p ON s.product_key = p.product_key;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"Design a database for an online retail platform tracking sales, inventory, and customer interactions\"\n",
    "ans = generate_database_schema(user_query,olap_context, llm_res, client)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = \"\"\" Tables\n",
    "\n",
    " 1. **Customers**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `customer_id` | `int` | Unique customer identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Customer name |\n",
    "| `email` | `varchar(255)` | Customer email |\n",
    "| `phone` | `varchar(20)` | Customer phone number |\n",
    "| `address` | `text` | Customer address |\n",
    "\n",
    " 2. **Products**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `product_id` | `int` | Unique product identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Product name |\n",
    "| `description` | `text` | Product description |\n",
    "| `price` | `decimal(10, 2)` | Product price |\n",
    "| `category_id` | `int` | Foreign key referencing the `Categories` table |\n",
    "\n",
    " 3. **Categories**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `category_id` | `int` | Unique category identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Category name |\n",
    "| `description` | `text` | Category description |\n",
    "\n",
    " 4. **Orders**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `order_id` | `int` | Unique order identifier (Primary Key) |\n",
    "| `customer_id` | `int` | Foreign key referencing the `Customers` table |\n",
    "| `order_date` | `date` | Order date |\n",
    "| `total` | `decimal(10, 2)` | Order total |\n",
    "\n",
    " 5. **Order Items**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `order_item_id` | `int` | Unique order item identifier (Primary Key) |\n",
    "| `order_id` | `int` | Foreign key referencing the `Orders` table |\n",
    "| `product_id` | `int` | Foreign key referencing the `Products` table |\n",
    "| `quantity` | `int` | Quantity of the product ordered |\n",
    "| `unit_price` | `decimal(10, 2)` | Unit price of the product |\n",
    "\n",
    " 6. **Inventory**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `product_id` | `int` | Foreign key referencing the `Products` table |\n",
    "| `quantity` | `int` | Current quantity in stock |\n",
    "| `warehouse_id` | `int` | Foreign key referencing the `Warehouses` table |\n",
    "\n",
    " 7. **Warehouses**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `warehouse_id` | `int` | Unique warehouse identifier (Primary Key) |\n",
    "| `name` | `varchar(255)` | Warehouse name |\n",
    "| `address` | `text` | Warehouse address |\n",
    "\n",
    " 8. **Sales**\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "| --- | --- | --- |\n",
    "| `sale_id` | `int` | Unique sale identifier (Primary Key) |\n",
    "| `order_id` | `int` | Foreign key referencing the `Orders` table |\n",
    "| `product_id` | `int` | Foreign key referencing the `Products` table |\n",
    "| `quantity` | `int` | Quantity sold |\n",
    "| `revenue` | `decimal(10, 2)` | Revenue generated from the sale |\n",
    "\n",
    " Relationships\n",
    "\n",
    "* A customer can place many orders (one-to-many).\n",
    "* An order is associated with one customer (many-to-one).\n",
    "* An order can have many order items (one-to-many).\n",
    "* An order item is associated with one order (many-to-one).\n",
    "* A product can be part of many order items (one-to-many).\n",
    "* An order item is associated with one product (many-to-one).\n",
    "* A product can have many sales (one-to-many).\n",
    "* A sale is associated with one product (many-to-one).\n",
    "* A warehouse can store many products (one-to-many).\n",
    "* A product can be stored in many warehouses (many-to-many).\n",
    "\n",
    " Indexes\n",
    "\n",
    "* Create indexes on the following columns:\n",
    "        + `Customers`: `name`, `email`, `phone`\n",
    "        + `Products`: `name`, `description`, `price`\n",
    "        + `Orders`: `order_date`, `total`\n",
    "        + `Order Items`: `quantity`, `unit_price`\n",
    "        + `Inventory`: `quantity`\n",
    "        + `Sales`: `quantity`, `revenue`\n",
    "\n",
    " Partitioning\n",
    "\n",
    "* Partition the `Orders` table by date (e.g., monthly).\n",
    "* Partition the `Sales` table by date (e.g., monthly).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 36, 'total_tokens': 61, 'completion_time': 0.090909091, 'prompt_time': 0.001931066, 'queue_time': 0.055213634, 'total_time': 0.092840157}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_41c250edc7', 'finish_reason': 'stop', 'logprobs': None}, id='run-291f33e9-b186-404e-85d1-faa1539713b3-0', usage_metadata={'input_tokens': 36, 'output_tokens': 25, 'total_tokens': 61})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = \"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\"\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name='llama-3.3-70b-versatile')\n",
    "response = llm.invoke(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GraphDocument(nodes=[Node(id='Customers', type='Table', properties={}), Node(id='Products', type='Table', properties={}), Node(id='Categories', type='Table', properties={}), Node(id='Orders', type='Table', properties={}), Node(id='Order Items', type='Table', properties={})], relationships=[Relationship(source=Node(id='Customers', type='Table', properties={}), target=Node(id='Orders', type='Table', properties={}), type='HAS_ORDERS', properties={}), Relationship(source=Node(id='Orders', type='Table', properties={}), target=Node(id='Order Items', type='Table', properties={}), type='CONTAINS_ORDER_ITEMS', properties={}), Relationship(source=Node(id='Order Items', type='Table', properties={}), target=Node(id='Products', type='Table', properties={}), type='CONTAINS_PRODUCTS', properties={}), Relationship(source=Node(id='Products', type='Table', properties={}), target=Node(id='Categories', type='Table', properties={}), type='BELONGS_TO_CATEGORY', properties={})], source=Document(metadata={}, page_content=' Tables\\n\\n 1. **Customers**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `customer_id` | `int` | Unique customer identifier (Primary Key) |\\n| `name` | `varchar(255)` | Customer name |\\n| `email` | `varchar(255)` | Customer email |\\n| `phone` | `varchar(20)` | Customer phone number |\\n| `address` | `text` | Customer address |\\n\\n 2. **Products**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `product_id` | `int` | Unique product identifier (Primary Key) |\\n| `name` | `varchar(255)` | Product name |\\n| `description` | `text` | Product description |\\n| `price` | `decimal(10, 2)` | Product price |\\n| `category_id` | `int` | Foreign key referencing the `Categories` table |\\n\\n 3. **Categories**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `category_id` | `int` | Unique category identifier (Primary Key) |\\n| `name` | `varchar(255)` | Category name |\\n| `description` | `text` | Category description |\\n\\n 4. **Orders**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `order_id` | `int` | Unique order identifier (Primary Key) |\\n| `customer_id` | `int` | Foreign key referencing the `Customers` table |\\n| `order_date` | `date` | Order date |\\n| `total` | `decimal(10, 2)` | Order total |\\n\\n 5. **Order Items**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `order_item_id` | `int` | Unique order item identifier (Primary Key) |\\n| `order_id` | `int` | Foreign key referencing the `Orders` table |\\n| `product_id` | `int` | Foreign key referencing the `Products` table |\\n| `quantity` |')), GraphDocument(nodes=[Node(id='Customer', type='Person', properties={}), Node(id='Order', type='Order', properties={}), Node(id='Order_Item', type='Order_item', properties={}), Node(id='Product', type='Product', properties={}), Node(id='Sale', type='Sale', properties={}), Node(id='Warehouse', type='Warehouse', properties={})], relationships=[Relationship(source=Node(id='Customer', type='Person', properties={}), target=Node(id='Order', type='Order', properties={}), type='PLACES', properties={}), Relationship(source=Node(id='Order', type='Order', properties={}), target=Node(id='Customer', type='Person', properties={}), type='ASSOCIATED_WITH', properties={}), Relationship(source=Node(id='Order', type='Order', properties={}), target=Node(id='Order_Item', type='Order_item', properties={}), type='HAS', properties={}), Relationship(source=Node(id='Order_Item', type='Order_item', properties={}), target=Node(id='Order', type='Order', properties={}), type='PART_OF', properties={}), Relationship(source=Node(id='Order_Item', type='Order_item', properties={}), target=Node(id='Product', type='Product', properties={}), type='CONTAINS', properties={}), Relationship(source=Node(id='Product', type='Product', properties={}), target=Node(id='Order_Item', type='Order_item', properties={}), type='PART_OF', properties={}), Relationship(source=Node(id='Product', type='Product', properties={}), target=Node(id='Sale', type='Sale', properties={}), type='SOLD', properties={}), Relationship(source=Node(id='Sale', type='Sale', properties={}), target=Node(id='Product', type='Product', properties={}), type='ASSOCIATED_WITH', properties={}), Relationship(source=Node(id='Warehouse', type='Warehouse', properties={}), target=Node(id='Product', type='Product', properties={}), type='STORES', properties={}), Relationship(source=Node(id='Product', type='Product', properties={}), target=Node(id='Warehouse', type='Warehouse', properties={}), type='STORED_IN', properties={})], source=Document(metadata={}, page_content='_id` | `int` | Foreign key referencing the `Products` table |\\n| `quantity` | `int` | Quantity of the product ordered |\\n| `unit_price` | `decimal(10, 2)` | Unit price of the product |\\n\\n 6. **Inventory**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `product_id` | `int` | Foreign key referencing the `Products` table |\\n| `quantity` | `int` | Current quantity in stock |\\n| `warehouse_id` | `int` | Foreign key referencing the `Warehouses` table |\\n\\n 7. **Warehouses**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `warehouse_id` | `int` | Unique warehouse identifier (Primary Key) |\\n| `name` | `varchar(255)` | Warehouse name |\\n| `address` | `text` | Warehouse address |\\n\\n 8. **Sales**\\n\\n| Column Name | Data Type | Description |\\n| --- | --- | --- |\\n| `sale_id` | `int` | Unique sale identifier (Primary Key) |\\n| `order_id` | `int` | Foreign key referencing the `Orders` table |\\n| `product_id` | `int` | Foreign key referencing the `Products` table |\\n| `quantity` | `int` | Quantity sold |\\n| `revenue` | `decimal(10, 2)` | Revenue generated from the sale |\\n\\n Relationships\\n\\n* A customer can place many orders (one-to-many).\\n* An order is associated with one customer (many-to-one).\\n* An order can have many order items (one-to-many).\\n* An order item is associated with one order (many-to-one).\\n* A product can be part of many order items (one-to-many).\\n* An order item is associated with one product (many-to-one).\\n* A product can have many sales (one-to-many).\\n* A sale is associated with one product (many-to-one).\\n* A warehouse can store many products (one-to-many).\\n* A product can be stored in many warehouses (many-to-many')), GraphDocument(nodes=[Node(id='Customers', type='Table', properties={}), Node(id='Products', type='Table', properties={}), Node(id='Orders', type='Table', properties={}), Node(id='Order Items', type='Table', properties={}), Node(id='Inventory', type='Table', properties={}), Node(id='Sales', type='Table', properties={}), Node(id='Indexes', type='Concept', properties={}), Node(id='Partitioning', type='Concept', properties={})], relationships=[Relationship(source=Node(id='Customers', type='Table', properties={}), target=Node(id='Indexes', type='Concept', properties={}), type='HAS_INDEXES', properties={}), Relationship(source=Node(id='Products', type='Table', properties={}), target=Node(id='Indexes', type='Concept', properties={}), type='HAS_INDEXES', properties={}), Relationship(source=Node(id='Orders', type='Table', properties={}), target=Node(id='Partitioning', type='Concept', properties={}), type='IS_PARTITIONED', properties={}), Relationship(source=Node(id='Sales', type='Table', properties={}), target=Node(id='Partitioning', type='Concept', properties={}), type='IS_PARTITIONED', properties={}), Relationship(source=Node(id='Orders', type='Table', properties={}), target=Node(id='Order Items', type='Table', properties={}), type='CONTAINS', properties={}), Relationship(source=Node(id='Products', type='Table', properties={}), target=Node(id='Inventory', type='Table', properties={}), type='IS_STORED_IN', properties={})], source=Document(metadata={}, page_content=' products (one-to-many).\\n* A product can be stored in many warehouses (many-to-many).\\n\\n Indexes\\n\\n* Create indexes on the following columns:\\n        + `Customers`: `name`, `email`, `phone`\\n        + `Products`: `name`, `description`, `price`\\n        + `Orders`: `order_date`, `total`\\n        + `Order Items`: `quantity`, `unit_price`\\n        + `Inventory`: `quantity`\\n        + `Sales`: `quantity`, `revenue`\\n\\n Partitioning\\n\\n* Partition the `Orders` table by date (e.g., monthly).\\n* Partition the `Sales` table by date (e.g., monthly).'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.schema import Document\n",
    "# Set your credentials\n",
    "NEO4J_URI = \"neo4j+s://791ec29e.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"sqJloNfV2JhYBEwkLVutmmv4kuKwOEnajD2qDkUgyBU\"\n",
    "\n",
    "# Initialize the graph with credentials\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "raw_document = [Document(page_content=raw_documents)]\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(raw_document[:3])\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "print(graph_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "def showGraph(cypher: str = default_cypher):\n",
    "    # Define Neo4j credentials directly\n",
    "    NEO4J_URI = \"neo4j+s://791ec29e.databases.neo4j.io\"\n",
    "    NEO4J_USERNAME = \"neo4j\"\n",
    "    NEO4J_PASSWORD = \"sqJloNfV2JhYBEwkLVutmmv4kuKwOEnajD2qDkUgyBU\"\n",
    "\n",
    "    # Create a Neo4j session to run queries\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri=NEO4J_URI,\n",
    "        auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    )\n",
    "    session = driver.session()\n",
    "    \n",
    "    # Execute Cypher query and visualize results\n",
    "    widget = GraphWidget(graph=session.run(cypher).graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    display(widget)\n",
    "    \n",
    "    return widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec723a14e16433995f80fc7f9a453d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='650px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec723a14e16433995f80fc7f9a453d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='650px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
